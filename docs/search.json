[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Aula10_quarto.html",
    "href": "Aula10_quarto.html",
    "title": "Correlação",
    "section": "",
    "text": "A correlação representa a associação entre duas variáveis respostas. As variáveis podem estar dissociadas ou apresentar associação fraca ou forte. O teste de correlação permite determinar qual é a correlação entre as as variáveis-resposta (uma por uma e de todas juntos).\nQuanto menos dispersos os dados, mais forte será a correlação entre duas variáveis.\nR (coeficiente de correlação de Pearson): varia entre -1 e 1, sendo que &lt; 0 uma correlação negativa e &gt; 0 uma correlação positiva. Quanto mais próximo de 1 ou -1, mais forte é a correlação.\nCorrelação =/= casualidade (na casualidade não existe uma verdadeira correlação entre elas de causa-efeito, é uma correlação espúria)\n\n\n\n\n\n\nImportant\n\n\n\nDiferente de regressão. Regressão é pra predizer que Y é em função de X. Usam o coeficiente de determinação R-quadrado.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(dplyr)\n\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\n\n\n\nUm gráfico de boxplot foi criado para visualizar a distribuição e a variabilidade dos dados.\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\n\nPosteriormente foram criados gráficos de dispersão entre cada variáveis respostas para visualizar se existe alguma correlação entre elas.\n\nimgs |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\nimgs |&gt; \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\nimgs |&gt; \n  ggplot(aes(LeafDoctor, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nO teste de correlação entre as variáveis pode ser executada usando a função cor().\n\ncor(imgs$Assess, imgs$LeafDoctor) #Dá o valor do coeficiente de correlação\n\n[1] 0.9666367\n\n\nO teste fornece o coeficiente de correlação, sendo igual a 0.966, indicando uma correlação positiva e forte.\nOutro teste pode ser realizado usando a função cor.test(). Essa função fornece um teste mais completo, com informações do coeficiente de correlação, intervalo de confiança e p-valor (Ho: coeficiente de relação = 0)\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\n\n\n\n\nNo pacote AgroR, pode ser usado a função corgraph() que fornece a matriz de correlação, com dados do coeficiente de correlação e a significância entre cada variável.\n\nimgs2 &lt;- imgs[, c(\"Assess\", \"LeafDoctor\", \"ImageJ\")]\n\nlibrary(AgroR)\ncorgraph(imgs2) \n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\nAtravés da matriz, percebe-se que a correlação entre as três variáveis respostas é forte.\nOutra alternativa de função é a corrplot() do pacote corrplot, que também fornece uma matriz de correlação.\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"lower\")\n\n\n\ncorrplot(cor_imgs2, method = \"circle\", type = \"lower\")"
  },
  {
    "objectID": "Aula10_quarto.html#importação-dos-dados",
    "href": "Aula10_quarto.html#importação-dos-dados",
    "title": "Correlação",
    "section": "",
    "text": "library(tidyverse)\nlibrary(gsheet)\nlibrary(dplyr)\n\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")"
  },
  {
    "objectID": "Aula10_quarto.html#visualização-dos-dados",
    "href": "Aula10_quarto.html#visualização-dos-dados",
    "title": "Correlação",
    "section": "",
    "text": "Um gráfico de boxplot foi criado para visualizar a distribuição e a variabilidade dos dados.\n\nimgs |&gt; \n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\n\nPosteriormente foram criados gráficos de dispersão entre cada variáveis respostas para visualizar se existe alguma correlação entre elas.\n\nimgs |&gt; \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\nimgs |&gt; \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\nimgs |&gt; \n  ggplot(aes(LeafDoctor, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "Aula10_quarto.html#teste-de-correlação",
    "href": "Aula10_quarto.html#teste-de-correlação",
    "title": "Correlação",
    "section": "",
    "text": "O teste de correlação entre as variáveis pode ser executada usando a função cor().\n\ncor(imgs$Assess, imgs$LeafDoctor) #Dá o valor do coeficiente de correlação\n\n[1] 0.9666367\n\n\nO teste fornece o coeficiente de correlação, sendo igual a 0.966, indicando uma correlação positiva e forte.\nOutro teste pode ser realizado usando a função cor.test(). Essa função fornece um teste mais completo, com informações do coeficiente de correlação, intervalo de confiança e p-valor (Ho: coeficiente de relação = 0)\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367"
  },
  {
    "objectID": "Aula10_quarto.html#usando-o-pacote-agror",
    "href": "Aula10_quarto.html#usando-o-pacote-agror",
    "title": "Correlação",
    "section": "",
    "text": "No pacote AgroR, pode ser usado a função corgraph() que fornece a matriz de correlação, com dados do coeficiente de correlação e a significância entre cada variável.\n\nimgs2 &lt;- imgs[, c(\"Assess\", \"LeafDoctor\", \"ImageJ\")]\n\nlibrary(AgroR)\ncorgraph(imgs2) \n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\nAtravés da matriz, percebe-se que a correlação entre as três variáveis respostas é forte.\nOutra alternativa de função é a corrplot() do pacote corrplot, que também fornece uma matriz de correlação.\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = \"number\", type = \"lower\")\n\n\n\ncorrplot(cor_imgs2, method = \"circle\", type = \"lower\")"
  },
  {
    "objectID": "Aula10_quarto.html#importação-dos-dados-1",
    "href": "Aula10_quarto.html#importação-dos-dados-1",
    "title": "Correlação",
    "section": "Importação dos dados",
    "text": "Importação dos dados\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nDo conjunto de dados acima, foram selecionados apenas as informações sobre as variáveis respostas.\n\ncampo2 &lt;- campo[, c(\"DFC\", \"FER\", \"PROD\")]\n\nFoi realizada a função corgraph().\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\nObserva-se que a PROD está mais fortemente correlacionada a DFC (associação negativa). A DFC e a FER estão associadas positivamente"
  },
  {
    "objectID": "Aula11_quarto.html",
    "href": "Aula11_quarto.html",
    "title": "Elaboração de Mapas",
    "section": "",
    "text": "Quando estamos trabalhando com algum dado, muitas vezes é necessário mostrar o local onde foi realizado o experimento. Através do Software R, é possível elaborar mapas que realizem essa função. Nesta página você irá aprender como criar mapas tradicionais, mapas indicando pontos de coordenadas e mapas interativos."
  },
  {
    "objectID": "Aula11_quarto.html#trabalhando-com-coordenadas",
    "href": "Aula11_quarto.html#trabalhando-com-coordenadas",
    "title": "Elaboração de Mapas",
    "section": "Trabalhando com coordenadas",
    "text": "Trabalhando com coordenadas\nPara criar um mapa que contenha os pontos de coordenadas, primeiramente é necessário ter um conjunto de dados que apresente as informações de latitude e longitude. Tendo esses dados, o mapa pode ser criado usando as funções ggplot() e geom_point().\nComo exemplo, foi utilizado o conjunto de dados RustSoybean integrado ao pacote r4pde. Esse conjunto de dados contém as informações de latitude e longitude de cada ponto. Ao criarmos um gráfico, as coordenadas são automaticamente reconhecidas pelo ggplot().\n\nsbr &lt;- RustSoybean\n\nsbr |&gt; \n  ggplot(aes(longitude, latitude))+\n  geom_point()+\n  coord_sf()\n\n\n\n\nAgora será adicionado esses pontos de coordenadas junto ao mapa do Brasil criado anteriormente.\n\nggplot(BRA)+\n  geom_sf(fill = \"green\",\n          color = \"black\",\n          linewidth = 1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"red\")\n\n\n\n\nPara retirar a grade do fundo do mapa, pode ser usado a função theme_map() do pacote ggthemes.\n\nggplot(BRA)+\n  geom_sf(fill = \"green\",\n          color = \"black\",\n          linewidth = 1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"red\")+\n  theme_map()\n\n\n\n\nPara adicionar a rosa-dos-ventos no mapa, pode ser usado a função annotation_north_arrow() do pacote ggspatial.\n\nggplot(BRA)+\n  geom_sf(fill = \"green\",\n          color = \"black\",\n          linewidth = 0.1)+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()+\n  annotation_north_arrow()\n\n\n\n\nCaso seja preciso destacar ou criar um mapa de apenas um estado, pode-se filtrar o estado desejado usando a função filter().\nNo caso abaixo, foi destacado apenas o estado de Minas Gerais.\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nggplot(BRA)+\n  geom_sf(fill = \"green\",\n          color = \"black\")+\n  geom_sf(data = MG, fill = \"yellow\")+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()\n\n\n\n\nNeste outro caso, foi criado um mapa apenas do estado de Minas Gerais.\n\nggplot(BRA)+\n  geom_sf(data = MG, fill = \"yellow\")+\n  theme_map()"
  },
  {
    "objectID": "Aula11_quarto.html#mapa-com-coordenadas-separadas-em-anos",
    "href": "Aula11_quarto.html#mapa-com-coordenadas-separadas-em-anos",
    "title": "Elaboração de Mapas",
    "section": "Mapa com coordenadas separadas em anos",
    "text": "Mapa com coordenadas separadas em anos\nCaso o conjunto de dados tenha diferentes pontos de coordenadas em diferentes anos de experimento, pode ser criado um mapa para cada ano.\nUsando o mesmo conjunto de dados RustSoybean, o primeiro passo foi separar as datas dos dados em dias, meses e anos (no conjunto de dados essas informações estão todas juntas, sendo necessário separá-las). Isso foi feito através da função separate()\nO segundo passo foi criar o mapa usando o conjunto de dados transformado e usar a função facet_wrap() para dividir os mapas em diferentes anos.\n\nsbr2 &lt;- sbr |&gt;\n  separate(planting, into = \n             c(\"year\", \"month\", \"day\"), sep = \"-\", remove = FALSE)\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"black\")+\n  geom_point(data = sbr2, aes(longitude,latitude, color = year), alpha = 0.5)+\n  facet_wrap(~year)+\n  theme_map()"
  },
  {
    "objectID": "Aula11_quarto.html#mapa-interativo-inteiro",
    "href": "Aula11_quarto.html#mapa-interativo-inteiro",
    "title": "Elaboração de Mapas",
    "section": "Mapa interativo inteiro",
    "text": "Mapa interativo inteiro\nUsando a função leaflet() do pacote leaflet, é possível criar um mapa interativo inteiro, que pode ser arrastado e tem as funções de zoom in e zoom out.\nAdicionando a função setView() é possível especificar os pontos de coordenada que você deseja usar. No exemplo abaixo foi colocado as coordenadas da cidade de Viçosa, MG.\n\nleaflet() |&gt; \n  addTiles()\n\n\n\n\nleaflet() |&gt; \n  addTiles() |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 15) #Viçosa\n\n\n\n\n\nSubstituindo a função addTiles() por addProviderTiles(), é possível mudar o modelo do mapa.\n\nleaflet() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5) #Viçosa"
  },
  {
    "objectID": "Aula11_quarto.html#trabalhando-com-coordenadas-1",
    "href": "Aula11_quarto.html#trabalhando-com-coordenadas-1",
    "title": "Elaboração de Mapas",
    "section": "Trabalhando com coordenadas",
    "text": "Trabalhando com coordenadas\nDo mesmo modo, também é possível criar esse tipo de mapa com pontos de coordenadas. Usando a função addCircleMarkers(), os pontos aparecem no mapa interativo inteiro.\nPara as coordenadas dos pontos, será utilizado o mesmo conjunto de dados trabalhado nos mapas anteriores.\n\nleaflet(sbr) |&gt; \n  addTiles() |&gt; \n  addCircleMarkers(radius = 1)"
  },
  {
    "objectID": "Aula1_quarto.html",
    "href": "Aula1_quarto.html",
    "title": "Introdução ao R",
    "section": "",
    "text": "R é uma linguagem de programação que vem se especializando na manipulação, análise e visualização de dados. Foi criado originalmente por Ross Ihaka e por Robert Gentleman no departamento de Estatística da Universidade de Auckland, Nova Zelândia.\nDentre as suas vantagens, pode-se destacar a sua adaptação aos sistemas operacionais Linux, Mac OS e Windows, sendo um programa de código livre e desenvolvido por seus próprios usuários, que criam documentos facilmente reprodutíveis e modificáveis. Além disso, possui uma comunidade extensa e ativa de usuários ao redor do mundo que todos os dias desenvolvem novas funcionalidades e pacotes para o programa e oferecem soluções para os problemas que possam surgir.\nO uso do software R é facilitado quando utilizamos o software RStudio, um ambiente de desenvolvimento integrado ao R, que apresenta uma interface gráfica mais amigável para o R, com muitos recursos úteis que facilitam a visualização do código R, a importação de conjunto de dados, a visualização de figuras, etc.\n\n\nComo o RStudio é uma interface para uso do R, ele deve ser instalado após a instalação do R.\nO R é instalado a partir da página do R na internet, que pode ser acessada clicando aqui.\nO RStudio é instalado em uma página separada, que pode ser acessada clicando aqui."
  },
  {
    "objectID": "Aula1_quarto.html#instalação-do-r-e-rstudio",
    "href": "Aula1_quarto.html#instalação-do-r-e-rstudio",
    "title": "Introdução ao R",
    "section": "",
    "text": "Como o RStudio é uma interface para uso do R, ele deve ser instalado após a instalação do R.\nO R é instalado a partir da página do R na internet, que pode ser acessada clicando aqui.\nO RStudio é instalado em uma página separada, que pode ser acessada clicando aqui."
  },
  {
    "objectID": "Aula1_quarto.html#rstudio-project",
    "href": "Aula1_quarto.html#rstudio-project",
    "title": "Introdução ao R",
    "section": "RStudio Project",
    "text": "RStudio Project\nAntes de começar a executar comandos no R, a criação de um RStudio Projects é uma ótima forma de manter o seu trabalho organizado. Ele mantém todos os scripts, documentos e dados em um único lugar, deixando-os separados de outros arquivos e projetos. Isso permite trabalhar com diferentes projetos ao mesmo tempo sem um interferir no outro.\nPara criar um novo projeto, é necessário clicar em File, depois New Project, escolher um Directory (pasta do arquivo) existente ou criar um novo e nomear o projeto."
  },
  {
    "objectID": "Aula1_quarto.html#chunk",
    "href": "Aula1_quarto.html#chunk",
    "title": "Introdução ao R",
    "section": "Chunk",
    "text": "Chunk\nO principal mecanismo para executar qualquer código no R envolve primeiro a criação de um chunk. O chunk permite que as funções e demais códigos sejam executadas e rodadas no documento. Um atalho que pode ser usado para sua criação é o Ctrl + Alt + I.\n\n\n\n\n\n\nNote\n\n\n\nQualquer código que tenha como função a importação, manipulação, análise e visualização de dados precisa ser realizado dentro de um chunk para que ele possa ser lido e executado pelo R!"
  },
  {
    "objectID": "Aula1_quarto.html#texto",
    "href": "Aula1_quarto.html#texto",
    "title": "Introdução ao R",
    "section": "Texto",
    "text": "Texto\nDurante a escrita, podemos colocar palavras em itálico usando 1 asterisco no início e no final da palavra, do mesmo modo podemos colocar palavras em negrito usando 2 asteriscos.\nPara criar títulos e subtítulos, podemos colocar “#” no início da frase. Um “#” representa o título, enquanto “##” e “###” representam subtítulos.\nDentro de um chunk, podemos colocar palavras e/ou frases entre aspas ou com um # na frente para que ele seja rodado como um texto, e não como dado."
  },
  {
    "objectID": "Aula1_quarto.html#estruturas-da-linguagem-r",
    "href": "Aula1_quarto.html#estruturas-da-linguagem-r",
    "title": "Introdução ao R",
    "section": "Estruturas da linguagem R",
    "text": "Estruturas da linguagem R\n\nValores ou values: são criadas pelo programador com a finalidade de salvar informações. As informações inseridas em um valor ficarão disponíveis para utilização enquanto o valor existir.\nFunções: são um conjunto de instruções pré-definidas que executam uma ou mais tarefas. Existem muitas funções já prontas para sua utilização, salvas em pacotes desenvolvidos para facilitar a criação de scripts. Quanto mais funções o programador conhecer, mais fácil será escrever seus scripts.\nOperadores: com os operadores fazemos operações matemáticas, como soma, divisão, multiplicação, etc.\nTipos de dados: numeric (números), characters (operações com letras, palavras, frases, etc.), factors (categorias) e logicals (verdadeiro ou falso). Esses são os tipos de dados básicos existentes na linguagem R.\nEstrutura de dados: vectors, que são uma sequência de dados do mesmo tipo. Lists, que são vetores com tipos de dados diferentes. Matrix, que possuem duas dimensões e um tipo de dado. Data frames, que são estruturas mais complexas, similares as planilhas do Excel e com tipos de dados diferentes.\nCondicional: No condicional If, dizemos que se algo é verdadeiro, uma ação deve ser realizada, se não é, outra será (ou nenhuma)."
  },
  {
    "objectID": "Aula1_quarto.html#atribuição-de-valores",
    "href": "Aula1_quarto.html#atribuição-de-valores",
    "title": "Introdução ao R",
    "section": "Atribuição de Valores",
    "text": "Atribuição de Valores\nQuando queremos atribuir um valor para algum nome, podemos utilizar &lt;-. Desse modo, se quisermos trabalhar com esses valores ou conjunto de valores atribuídos a um nome, podemos utilizar diretamente o nome, sem precisar repetir o valor.\n\nx &lt;- 10\nx\n\n[1] 10\n\ny &lt;- x*10\ny\n\n[1] 100\n\nz &lt;- x*y\nz\n\n[1] 1000"
  },
  {
    "objectID": "Aula1_quarto.html#conjunto-de-valores-e-data-frame",
    "href": "Aula1_quarto.html#conjunto-de-valores-e-data-frame",
    "title": "Introdução ao R",
    "section": "Conjunto de valores e data frame",
    "text": "Conjunto de valores e data frame\nPara criar um conjunto de valores, pode-se utilizar c()e colocar os valores desejados. Caso os valores sejam contínuos, pode-se agrupá-los usando :, desse modo o conjunto será formado por todos os valores que estão entre os dois números colocados.\n\nA &lt;- c(1:10)\nA\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nB &lt;- c(11:20)\nB\n\n [1] 11 12 13 14 15 16 17 18 19 20\n\n\nO data frame é uma estrutura em que os dados podem ser organizados em formato de tabela. Ele pode ser criado por meio da junção de dois ou mais conjunto de dados, usando a função data.frame(), mas, para isso, o número de valores presentes nos conjuntos deve ser o mesmo.\n\ndf &lt;- data.frame(A,B)\ndf\n\n    A  B\n1   1 11\n2   2 12\n3   3 13\n4   4 14\n5   5 15\n6   6 16\n7   7 17\n8   8 18\n9   9 19\n10 10 20"
  },
  {
    "objectID": "Aula1_quarto.html#pipe",
    "href": "Aula1_quarto.html#pipe",
    "title": "Introdução ao R",
    "section": "Pipe",
    "text": "Pipe\nQuando quisermos que todas as funções executadas estejam se referindo a um determinado data frame sem precisar chamá-lo repetidamente, podemos usar um pipe. O pipe, executado por |&gt;ou %&gt;%, indica que todas as funções abaixo dele estão se referindo ao data frame especificado. Um atalho para a criação do pipe é Ctrl + Shift + M.\n\ndf2 &lt;- cars\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ndf2$dist2 &lt;- c(1:50) # O $ é usado para criar uma nova coluna dentro do df2\ndf2\n\n   speed dist dist2\n1      4    2     1\n2      4   10     2\n3      7    4     3\n4      7   22     4\n5      8   16     5\n6      9   10     6\n7     10   18     7\n8     10   26     8\n9     10   34     9\n10    11   17    10\n11    11   28    11\n12    12   14    12\n13    12   20    13\n14    12   24    14\n15    12   28    15\n16    13   26    16\n17    13   34    17\n18    13   34    18\n19    13   46    19\n20    14   26    20\n21    14   36    21\n22    14   60    22\n23    14   80    23\n24    15   20    24\n25    15   26    25\n26    15   54    26\n27    16   32    27\n28    16   40    28\n29    17   32    29\n30    17   40    30\n31    17   50    31\n32    18   42    32\n33    18   56    33\n34    18   76    34\n35    18   84    35\n36    19   36    36\n37    19   46    37\n38    19   68    38\n39    20   32    39\n40    20   48    40\n41    20   52    41\n42    20   56    42\n43    20   64    43\n44    22   66    44\n45    23   54    45\n46    24   70    46\n47    24   92    47\n48    24   93    48\n49    24  120    49\n50    25   85    50\n\nlibrary(tidyverse)\n\ndf2 |&gt;\n  mutate(dist3 = dist2+1) |&gt; \n  select(1)\n\n   speed\n1      4\n2      4\n3      7\n4      7\n5      8\n6      9\n7     10\n8     10\n9     10\n10    11\n11    11\n12    12\n13    12\n14    12\n15    12\n16    13\n17    13\n18    13\n19    13\n20    14\n21    14\n22    14\n23    14\n24    15\n25    15\n26    15\n27    16\n28    16\n29    17\n30    17\n31    17\n32    18\n33    18\n34    18\n35    18\n36    19\n37    19\n38    19\n39    20\n40    20\n41    20\n42    20\n43    20\n44    22\n45    23\n46    24\n47    24\n48    24\n49    24\n50    25"
  },
  {
    "objectID": "Aula1_quarto.html#renderização",
    "href": "Aula1_quarto.html#renderização",
    "title": "Introdução ao R",
    "section": "Renderização",
    "text": "Renderização\nPara transformar esse documento .qmd em HTML ou em outros formatos, é necessário renderizar o documento. Para isso basta clicar no Render para que o documento ou site seja criado.\n\n\n\n\n\n\nQuer saber mais sobre o R?\n\n\n\nAcesse esses livros e sites para mais informações sobre o R: - R for Data Science - The Art of Data Science - An Introduction to R"
  },
  {
    "objectID": "Aula2_quarto.html",
    "href": "Aula2_quarto.html",
    "title": "Pacotes",
    "section": "",
    "text": "O que são pacotes?\nOs packages ou pacotes são conjunto de funções, dados e documentações que podem ser instalados a fim de estender a funcionalidade do R.\nPara instalar novos pacotes, usamos a função install.packages()e chamamos o nome do pacote desejado. Outra forma de instalar pacotes é clicar na aba Packages do painel localizado à direita inferior e clicar no Install. Na janela aberta, é preciso apenas escrever o nome do pacote e instalar.\n\n#install.packages(\"agricolae\")\n\n\n\nLibrary\nPara que o pacote instalado seja ativado e possa ser utilizado no nosso arquivo, é necessário chamá-lo pela função library(). Essa função irá ativar o pacote, permitindo que todas as funções e dados contidos no pacote estejam disponíveis para o uso.\nNo exemplo abaixo iremos chamar o pacote agricolae, que foi previamente instalado. Com o pacote ativado, podemos usar uma de suas funções: o audpc() (usado para calcular a área abaixo da curva de progresso da doença).\n\nlibrary(agricolae)\n\ndates&lt;-c(14,21,28)\nevaluation&lt;-c(40,80,90)\naudpc(evaluation,dates)\n\nevaluation \n      1015 \n\n\n\n\nUsando o help\nPara tirar dúvida de como um pacote funciona e quais são as funções e dados presentes dentro dele, pode-se utilizar ? com o nome do pacote para aparecer todas as informações pertinentes sobre ele. Para aprender sobre uma determinada função, pode-se utilizar também ??.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Aula3_quarto.html",
    "href": "Aula3_quarto.html",
    "title": "Importação de Dados",
    "section": "",
    "text": "Quando já temos um conjunto de dados obtido através da avaliação de um experimento, o primeiro passo que deve ser realizado para que possamos trabalhar com esses dados é sua importação.\n\n\nSe quisermos trabalhar com dados já prontos e disponíveis dentro de um pacote do R, podemos apenas instalar o pacote desejado, ativá-lo com o library() e atribuir algum dado disponível dele a um nome. Como exemplo, instalamos o pacote ec50estimator e importamos um dado já presente nesse pacote, o multi_isolate.\n\nlibrary(ec50estimator)\ndf1 &lt;- multi_isolate\n\n\n\n\nPara dados que estão em um arquivo Excel, a sua importação pode ser feita usando a função read_excel() do pacote readxl. Nessa função, colocamos o nome do arquivo em Excel entre aspas e a sua terminação com o formato desse arquivo .xlsx.\nEssa função irá sempre abrir a primeira planilha presente no arquivo, portanto, caso for preciso abrir outra planilha, podemos usar dentro da função read_excel() o argumento sheet =, onde será especificado o nome da planilha que se deseja importar.\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"escala\")\n\nEm casos em que o arquivo estiver no formato .csv(valores separados por vírgulas), podemos utilizar a função read.csv() do pacote tidyverse e colocar o nome do arquivo entre aspas, assim como foi feito na função anterior.\n\nlibrary(tidyverse)\ndf3 &lt;- read.csv(\"dados-diversos.csv\")\n\n\n\n\nPodemos ainda importar dados do Google Sheets. Nesse caso não temos um arquivo próprio para armazenar esses dados, pois eles estão contidos dentro de um link na web. Para a importação desses dados, podemos usar o pacote gsheet e a sua função gsheet2tbl(). Nessa função, ao invés do nome do arquivo, é colocado o endereço da página onde estão os dados, também entre aspas. Caso seja necessário importar outra planilha, podemos usar a mesma função apenas trocando o endereço da página.\nO pacote googlesheet4 também pode ser utilizado para importar dados do Google Sheets. A sua função é read_sheet(), no qual também é colocado entre aspas o endereço da página.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\ndf41 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=866852711#gid=866852711\")\n\n\n\n\nNessa aula iremos aprender outra forma de importar os dados, através do pacote datapasta. Instalando o pacote, ele fornece mais opções na aba Addins (situada logo abaixo de “Help” no canto superior da tela). Por meio do Addins podemos copiar (Ctrl+C) algum dado, vetor ou tabela e colar dentro do chunk no documento R Quarto Markdown. Para colar essas informações, selecionamos o Addins e podemos selecionar “Paste as” conforme o que desejarmos, sendo vector uma coluna e data.frame como uma tabela.\n\nlibrary(datapasta)\n\ncomp &lt;- c(\"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\n\ndat &lt;- data.frame(\n  stringsAsFactors = FALSE,\n              trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                       \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\n                       \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                       \"control\",\"control\",\"control\"),\n               rep = c(1L,2L,3L,4L,5L,6L,7L,8L,\n                       9L,10L,1L,2L,3L,4L,5L,6L,7L,8L,9L,10L),\n              comp = c(9,12.5,10,8,13.2,11,10.8,\n                       9.5,10.8,10.4,13.72,15.91,15.7,14.2,15.9,16.54,\n                       18,14.4,16.41,16))\ndat\n\n      trat rep  comp\n1      Mg2   1  9.00\n2      Mg2   2 12.50\n3      Mg2   3 10.00\n4      Mg2   4  8.00\n5      Mg2   5 13.20\n6      Mg2   6 11.00\n7      Mg2   7 10.80\n8      Mg2   8  9.50\n9      Mg2   9 10.80\n10     Mg2  10 10.40\n11 control   1 13.72\n12 control   2 15.91\n13 control   3 15.70\n14 control   4 14.20\n15 control   5 15.90\n16 control   6 16.54\n17 control   7 18.00\n18 control   8 14.40\n19 control   9 16.41\n20 control  10 16.00\n\ndat.tib &lt;- tibble::tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,  12.5,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,  13.2,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,  10.8,\n      \"Mg2\",   8L,   9.5,\n      \"Mg2\",   9L,  10.8,\n      \"Mg2\",  10L,  10.4,\n  \"control\",   1L, 13.72,\n  \"control\",   2L, 15.91,\n  \"control\",   3L,  15.7,\n  \"control\",   4L,  14.2,\n  \"control\",   5L,  15.9,\n  \"control\",   6L, 16.54,\n  \"control\",   7L,    18,\n  \"control\",   8L,  14.4,\n  \"control\",   9L, 16.41,\n  \"control\",  10L,    16\n  )\ndat.tib\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\nvisitas &lt;- tibble::tribble(\n           ~Paises, ~Visitas,\n          \"Brazil\",     4303,\n      \"Mozambique\",       43,\n        \"Portugal\",       33,\n   \"United States\",       23,\n          \"Angola\",       19,\n           \"Spain\",       16,\n       \"(not set)\",       12,\n        \"Colombia\",        8,\n         \"Germany\",        5,\n         \"Hungary\",        5,\n  \"United Kingdom\",        5,\n     \"Netherlands\",        4,\n         \"Ecuador\",        3,\n          \"France\",        3,\n           \"Chile\",        2,\n        \"Paraguay\",        2,\n            \"Peru\",        2,\n       \"Argentina\",        1,\n         \"Austria\",        1,\n         \"Bolivia\",        1,\n      \"Cape Verde\",        1,\n           \"China\",        1,\n           \"Egypt\",        1,\n         \"Finland\",        1,\n           \"India\",        1,\n           \"Italy\",        1,\n        \"Malaysia\",        1,\n        \"Pakistan\",        1,\n          \"Poland\",        1,\n       \"Singapore\",        1,\n     \"Timor-Leste\",        1,\n         \"Uruguay\",        1\n  )"
  },
  {
    "objectID": "Aula3_quarto.html#importando-dados-de-pacotes",
    "href": "Aula3_quarto.html#importando-dados-de-pacotes",
    "title": "Importação de Dados",
    "section": "",
    "text": "Se quisermos trabalhar com dados já prontos e disponíveis dentro de um pacote do R, podemos apenas instalar o pacote desejado, ativá-lo com o library() e atribuir algum dado disponível dele a um nome. Como exemplo, instalamos o pacote ec50estimator e importamos um dado já presente nesse pacote, o multi_isolate.\n\nlibrary(ec50estimator)\ndf1 &lt;- multi_isolate"
  },
  {
    "objectID": "Aula3_quarto.html#importando-dados-do-excel",
    "href": "Aula3_quarto.html#importando-dados-do-excel",
    "title": "Importação de Dados",
    "section": "",
    "text": "Para dados que estão em um arquivo Excel, a sua importação pode ser feita usando a função read_excel() do pacote readxl. Nessa função, colocamos o nome do arquivo em Excel entre aspas e a sua terminação com o formato desse arquivo .xlsx.\nEssa função irá sempre abrir a primeira planilha presente no arquivo, portanto, caso for preciso abrir outra planilha, podemos usar dentro da função read_excel() o argumento sheet =, onde será especificado o nome da planilha que se deseja importar.\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"escala\")\n\nEm casos em que o arquivo estiver no formato .csv(valores separados por vírgulas), podemos utilizar a função read.csv() do pacote tidyverse e colocar o nome do arquivo entre aspas, assim como foi feito na função anterior.\n\nlibrary(tidyverse)\ndf3 &lt;- read.csv(\"dados-diversos.csv\")"
  },
  {
    "objectID": "Aula3_quarto.html#importando-dados-do-google-sheets",
    "href": "Aula3_quarto.html#importando-dados-do-google-sheets",
    "title": "Importação de Dados",
    "section": "",
    "text": "Podemos ainda importar dados do Google Sheets. Nesse caso não temos um arquivo próprio para armazenar esses dados, pois eles estão contidos dentro de um link na web. Para a importação desses dados, podemos usar o pacote gsheet e a sua função gsheet2tbl(). Nessa função, ao invés do nome do arquivo, é colocado o endereço da página onde estão os dados, também entre aspas. Caso seja necessário importar outra planilha, podemos usar a mesma função apenas trocando o endereço da página.\nO pacote googlesheet4 também pode ser utilizado para importar dados do Google Sheets. A sua função é read_sheet(), no qual também é colocado entre aspas o endereço da página.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\ndf41 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=866852711#gid=866852711\")"
  },
  {
    "objectID": "Aula3_quarto.html#importando-dados-através-do-pacote-datapasta",
    "href": "Aula3_quarto.html#importando-dados-através-do-pacote-datapasta",
    "title": "Importação de Dados",
    "section": "",
    "text": "Nessa aula iremos aprender outra forma de importar os dados, através do pacote datapasta. Instalando o pacote, ele fornece mais opções na aba Addins (situada logo abaixo de “Help” no canto superior da tela). Por meio do Addins podemos copiar (Ctrl+C) algum dado, vetor ou tabela e colar dentro do chunk no documento R Quarto Markdown. Para colar essas informações, selecionamos o Addins e podemos selecionar “Paste as” conforme o que desejarmos, sendo vector uma coluna e data.frame como uma tabela.\n\nlibrary(datapasta)\n\ncomp &lt;- c(\"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\n\ndat &lt;- data.frame(\n  stringsAsFactors = FALSE,\n              trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                       \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\n                       \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                       \"control\",\"control\",\"control\"),\n               rep = c(1L,2L,3L,4L,5L,6L,7L,8L,\n                       9L,10L,1L,2L,3L,4L,5L,6L,7L,8L,9L,10L),\n              comp = c(9,12.5,10,8,13.2,11,10.8,\n                       9.5,10.8,10.4,13.72,15.91,15.7,14.2,15.9,16.54,\n                       18,14.4,16.41,16))\ndat\n\n      trat rep  comp\n1      Mg2   1  9.00\n2      Mg2   2 12.50\n3      Mg2   3 10.00\n4      Mg2   4  8.00\n5      Mg2   5 13.20\n6      Mg2   6 11.00\n7      Mg2   7 10.80\n8      Mg2   8  9.50\n9      Mg2   9 10.80\n10     Mg2  10 10.40\n11 control   1 13.72\n12 control   2 15.91\n13 control   3 15.70\n14 control   4 14.20\n15 control   5 15.90\n16 control   6 16.54\n17 control   7 18.00\n18 control   8 14.40\n19 control   9 16.41\n20 control  10 16.00\n\ndat.tib &lt;- tibble::tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,  12.5,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,  13.2,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,  10.8,\n      \"Mg2\",   8L,   9.5,\n      \"Mg2\",   9L,  10.8,\n      \"Mg2\",  10L,  10.4,\n  \"control\",   1L, 13.72,\n  \"control\",   2L, 15.91,\n  \"control\",   3L,  15.7,\n  \"control\",   4L,  14.2,\n  \"control\",   5L,  15.9,\n  \"control\",   6L, 16.54,\n  \"control\",   7L,    18,\n  \"control\",   8L,  14.4,\n  \"control\",   9L, 16.41,\n  \"control\",  10L,    16\n  )\ndat.tib\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\nvisitas &lt;- tibble::tribble(\n           ~Paises, ~Visitas,\n          \"Brazil\",     4303,\n      \"Mozambique\",       43,\n        \"Portugal\",       33,\n   \"United States\",       23,\n          \"Angola\",       19,\n           \"Spain\",       16,\n       \"(not set)\",       12,\n        \"Colombia\",        8,\n         \"Germany\",        5,\n         \"Hungary\",        5,\n  \"United Kingdom\",        5,\n     \"Netherlands\",        4,\n         \"Ecuador\",        3,\n          \"France\",        3,\n           \"Chile\",        2,\n        \"Paraguay\",        2,\n            \"Peru\",        2,\n       \"Argentina\",        1,\n         \"Austria\",        1,\n         \"Bolivia\",        1,\n      \"Cape Verde\",        1,\n           \"China\",        1,\n           \"Egypt\",        1,\n         \"Finland\",        1,\n           \"India\",        1,\n           \"Italy\",        1,\n        \"Malaysia\",        1,\n        \"Pakistan\",        1,\n          \"Poland\",        1,\n       \"Singapore\",        1,\n     \"Timor-Leste\",        1,\n         \"Uruguay\",        1\n  )"
  },
  {
    "objectID": "Aula4_quarto.html",
    "href": "Aula4_quarto.html",
    "title": "Análise exploratória 1",
    "section": "",
    "text": "Após a importação de um conjunto de dados, uma análise exploratória com montagem de gráficos pode ser feita com o objetivo de analisar e resumir os dados. Para a criação do gráfico, pode ser usada a função ggplot() do pacote tidyverse. Dentro dessa função, é possível ir modificando o gráfico como desejar por meio dos seus argumentos. Usa-se o argumento aes()para especificar qual das variáveis irá compor o eixo X e eixo Y do gráfico. Por exemplo, ao colocar aes(trat,comp) está especificando que a variável trat representará o eixo X e a variável comp representará o eixo Y.\nPara continuar adicionando funções dentro de um mesmo pipe, deve-se colocar o sinal +. O tipo de gráfico que será criado dependerá da função geom_, podendo ser um gráfico de pontos se usar geom_point() ou um gráfico boxplot se usar geom_boxplot(). Há também vários outros tipos que podem ser utilizados dependendo da função."
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-o-gráfico-de-pontos",
    "href": "Aula4_quarto.html#trabalhando-com-o-gráfico-de-pontos",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com o gráfico de pontos",
    "text": "Trabalhando com o gráfico de pontos\nDentro da função geom_point, determina-se a cor dos pontos com o argumento color =, o formato dos pontos com o argumento shape = e o tamanho dos pontos com o argumento size =.\n\ng1 &lt;- dados|&gt;\n  ggplot(aes(trat, comp))+\n  geom_point(color = \"black\", shape = 2, size = 3)\ng1\n\n\n\n\n\nTemas e legendas\nOutras adições que podem ser feitas com o gráfico é modificar o seu tema e adicionar títulos e legendas. Existem diversas funções para modificar o tema do gráfico, entre eles o theme_classic() ou então o theme_bw(). Para adicionar algum texto no gráfico, usa-se a função labs(), com isso pode-se adicionar um nome para o eixo X e para o eixo Y e também adicionar um título para o gráfico e uma legenda.\n\ng1 + theme_classic() +\n  labs(x = \"Tratamento\",\n       y = \"Comprimento\",\n       title = \"Meu primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")"
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-boxplot",
    "href": "Aula4_quarto.html#trabalhando-com-boxplot",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com boxplot",
    "text": "Trabalhando com boxplot\nAlém do geom_point() é possível usar também o geom_boxplot() para criar um gráfico boxplot ou o geom_jitter() para criar um gráfico de pontos separados, não agrupados. No geom_boxplot() tem os argumentos outlier.colour = NA para não duplicar o outlier e o fill = para adicionar uma cor ao quadrado do boxplot.\nNo geom_jitter() pode ser usado os argumentos width = para modificar a largura, color = para mudar a cor, shape = para mudar o formato e size = para mudar o tamanho dos pontos.\nAs funções ylim() e scale_y_continuous() podem ser usados para definir ou delimitar os valores que aparecem no eixo Y.\n\ng2 &lt;- dados |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot(outlier.colour = NA,\n               fill = \"orange\")+\n  geom_jitter(width = 0.05, \n              color = \"black\",\n              shape = 1,\n              size = 3) \n\ng2 + theme_classic()+\n  labs(x = \"Tratamento\",\n       y = \"Comprimento (mm)\",\n       title = \"Meu primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")+\n  ylim(0,20) +\n  scale_y_continuous(limits = c(0,20),\n                     n.breaks = 10)"
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-histogramas-sobre-a-incidência",
    "href": "Aula4_quarto.html#trabalhando-com-histogramas-sobre-a-incidência",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com histogramas sobre a incidência",
    "text": "Trabalhando com histogramas sobre a incidência\nPara visualizar esse conjunto de dados, pode ser feito uma análise exploratória utilizando o histograma. O histograma serve para visualizar uma distribuição contínua apresentado as frequências de determinados resultados. Para criar o histograma, usa-se a função ggplot() juntamente com geom_histogram(). Como o conjunto de dados se refere a 2 regiões diferentes, pode-se realizar um histograma por região usando o facet_wrap(~region), dessa forma as duas regiões ficam separadas.\n\ncr |&gt; \n  ggplot(aes(x = inc))+\n  geom_histogram()+\n  facet_wrap(~region)"
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-boxplot-sobre-a-incidência",
    "href": "Aula4_quarto.html#trabalhando-com-boxplot-sobre-a-incidência",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com boxplot sobre a incidência",
    "text": "Trabalhando com boxplot sobre a incidência\nTambém pode ser observado os dados através de um gráfico em boxplot. Cria-se esse gráfico com a função geom_boxplot(). O boxplot irá fornecer a variação de dados observados de uma variável numérica por meio de quartis, sendo que a caixa é delimitada pelo primeiro e terceiro quartil e a linha dentro da caixa representa a mediana.\nOs valores da mediana e do primeiro e terceiro quartil podem ser encontrados através da função summary().\n\ncr |&gt; \n  ggplot(aes(y = inc))+\n  geom_boxplot()\n\n\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71"
  },
  {
    "objectID": "Aula4_quarto.html#sumário-da-incidência",
    "href": "Aula4_quarto.html#sumário-da-incidência",
    "title": "Análise exploratória 1",
    "section": "Sumário da incidência",
    "text": "Sumário da incidência\nPara observar valores como média, desvio padrão e mediana, pode ser usado a função summerise()e os argumentos mean(), sd() e median(). Mas antes disso, será agrupado os dados pela região, separando dessa forma as duas regiões diferentes novamente. Isso pode ser feito com a função group_by().\n\ncr |&gt; \n  group_by(region) |&gt; \n  summarise(inc_mean = mean(inc),\n            sd_mean = sd(inc),\n            inc_med = median(inc))\n\n# A tibble: 2 × 4\n  region inc_mean sd_mean inc_med\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Oromia     37.0    14.6    39.5\n2 SNNPR      33.4    18.9    29.6\n\n\nPosteriormente, também foi feito a sumarização agrupando os dados à nível de cultivar.\n\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarise(inc_mean = mean(inc),\n            sd_mean = sd(inc),\n            inc_med = median(inc))\n\n# A tibble: 3 × 4\n  cultivar inc_mean sd_mean inc_med\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4    5.66    15.2\n2 Local        53.4   14.3     50.9\n3 Mixture      31.9   11.2     31.6"
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-gráfico-de-dispersão-entre-incidência-e-severidade",
    "href": "Aula4_quarto.html#trabalhando-com-gráfico-de-dispersão-entre-incidência-e-severidade",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com gráfico de dispersão entre incidência e severidade",
    "text": "Trabalhando com gráfico de dispersão entre incidência e severidade\nTambém pode ser criado um gráfico de dispersão para mostrar a relação entre incidência e severidade, usando a função geom_point(). O gráfico de dispersão de pontos é um tipo de gráfico que pode ser utilizado quando as variáveis X e Y são contínuas e apresentam relação entre as respostas.\n\ncr |&gt; \n  ggplot(aes(inc, sev2))+\n  geom_point()\n\n\n\n\nPor meio desse gráfico, é possível observar que conforme a incidência aumenta, a severidade também aumenta."
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-histogramas-e-sumário-de-severidade",
    "href": "Aula4_quarto.html#trabalhando-com-histogramas-e-sumário-de-severidade",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com histogramas e sumário de severidade",
    "text": "Trabalhando com histogramas e sumário de severidade\nDo mesmo modo, foi feito um histograma sobre a variável severidade separando as duas regiões.\n\ncr |&gt; \n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\nTambém foi feito a sumarização da severidade agrupando os dados à nível de cultivar.\n\ncr |&gt; \n  group_by(cultivar) |&gt; \n  summarise(sev_mean = mean(sev2),\n            sev_sd = sd(sev2),\n            sev_med = median(sev2))\n\n# A tibble: 3 × 4\n  cultivar sev_mean sev_sd sev_med\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     2.16   1.82    1.64\n2 Local       18.7   11.1    17.2 \n3 Mixture      6.47   4.35    5.43\n\n\nAo criar um histograma sobre a variável severidade agrupando os dados em função da cultivar, pode-se notar que a distribuição da severidade é mais simétrica\n\ncr |&gt; \n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(~cultivar)"
  },
  {
    "objectID": "Aula4_quarto.html#trabalhando-com-histograma-sobre-severidade-por-região-e-cultivar",
    "href": "Aula4_quarto.html#trabalhando-com-histograma-sobre-severidade-por-região-e-cultivar",
    "title": "Análise exploratória 1",
    "section": "Trabalhando com histograma sobre severidade por região e cultivar",
    "text": "Trabalhando com histograma sobre severidade por região e cultivar\nPara comparar os histogramas de severidade agrupados por região e por cultivar, pode-se colocar o argumento facet_grid(region ~ cultivar). Desse modo, ele irá criar um histograma para cada relação entre os níveis de região e cultivar.\nNo gráfico abaixo foi utilizado a função scale_fill_colorblind() do pacote ggthemes para adicionar cores ao gráfico.\n\nlibrary(ggthemes)\n\ncr |&gt; \n  ggplot(aes(x = sev2, fill = region))+\n  geom_histogram(color = \"white\")+\n  facet_grid(region ~ cultivar)+\n  scale_fill_colorblind()+\n  theme_minimal(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\", fill = \"Region\")"
  },
  {
    "objectID": "Aula4_quarto.html#criando-subconjuntos-com-select-e-filter",
    "href": "Aula4_quarto.html#criando-subconjuntos-com-select-e-filter",
    "title": "Análise exploratória 1",
    "section": "Criando subconjuntos com select e filter",
    "text": "Criando subconjuntos com select e filter\nA função select() é feita para selecionar colunas, enquanto a função filter() é feita para filtrar linhas. Usando essas funções do pacote dplyr, será criado subconjuntos: o primeiro irá agrupar os dados sobre as fazendas, cultivares e severidade referentes à região de Oromia enquanto que o segundo irá agrupar essas mesmas informações referentes à região de SNNPR.\n\n# Subconjunto Oromia\ncr_oromia &lt;- cr |&gt; \n  select(farm, region, cultivar, sev2) |&gt; \n  filter(region == \"Oromia\")\ncr_oromia\n\n# A tibble: 165 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1   286 Oromia Mixture   7.63\n 2   287 Oromia Mixture   9.39\n 3   288 Oromia Mixture   1.30\n 4   289 Oromia Mixture   9.79\n 5   290 Oromia Local    18.5 \n 6   291 Oromia Mixture  13.2 \n 7   292 Oromia Mixture   5.60\n 8   293 Oromia Mixture   1.06\n 9   294 Oromia Local    17.6 \n10   295 Oromia Mixture  15.4 \n# ℹ 155 more rows\n\n# Subconjunto SNNPR\ncr_pr &lt;- cr |&gt; \n  select(farm, region, cultivar, sev2) |&gt; \n  filter(region == \"SNNPR\")\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows"
  },
  {
    "objectID": "Aula4_quarto.html#visualização-dos-subconjuntos",
    "href": "Aula4_quarto.html#visualização-dos-subconjuntos",
    "title": "Análise exploratória 1",
    "section": "Visualização dos subconjuntos",
    "text": "Visualização dos subconjuntos\nTendo criado os subconjuntos, foi feito um gráfico boxplot para a visualização de cada um deles.\n\np1 &lt;- cr_oromia |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  coord_flip()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")\np1\n\n\n\np2 &lt;- cr_pr |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  coord_flip()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")\np2"
  },
  {
    "objectID": "Aula4_quarto.html#juntando-gráficos-com-o-patchwork",
    "href": "Aula4_quarto.html#juntando-gráficos-com-o-patchwork",
    "title": "Análise exploratória 1",
    "section": "Juntando gráficos com o patchwork",
    "text": "Juntando gráficos com o patchwork\nAtravés do pacote patchwork, é possível juntar dois ou mais gráficos em uma única imagem. Os gráficos podem ficar um do lado do outro\n\nlibrary(patchwork)\n\np1 + p2\n\n\n\n\nOu também um em cima do outro.\n\np1 / p2\n\n\n\n\nPara que os gráficos compartilhem a mesma legenda e o mesmo nome dos eixos, pode ser usado as funções plot_layout() e plot_annotation().\n\n(p1 / p2) + \n  plot_layout(guides = \"collect\",\n              axes = \"collect\")+\n  plot_annotation(tag_levels = 'A')\n\n\n\n\nAdicionando as funções theme_few() e scale_fill_few() é possível alterar o tema e as cores do gráfico.\n\np11 &lt;- cr_oromia |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  theme_few()+           #Para mudar o formato/estilo do gráfico\n  scale_fill_few()+   #Para mudar a cor\n  coord_flip()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")\np11\n\n\n\np22 &lt;- cr_pr |&gt; \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  theme_few()+           #Para mudar o formato/estilo do gráfico\n  scale_fill_few()+   #Para mudar a cor\n  coord_flip()+\n  labs(x = \"Cultivar\",\n       y = \"Severity (%)\")\np22\n\n\n\n\nColocando título e fonte na imagem.\n\n(p11 / p22) + \n  plot_layout(guides = \"collect\",\n              axes = \"collect\")+\n  plot_annotation(title = \"Coffe rust in Ethiopia\",\n                  caption = \"Source: Del Ponte (2022)\",\n                  tag_levels = 'A')"
  },
  {
    "objectID": "Aula4_quarto.html#colocando-um-gráfico-dentro-de-outro",
    "href": "Aula4_quarto.html#colocando-um-gráfico-dentro-de-outro",
    "title": "Análise exploratória 1",
    "section": "Colocando um gráfico dentro de outro",
    "text": "Colocando um gráfico dentro de outro\nUsando ainda o pacote patchwork, é possível inserir um gráfico dentro de outro gráfico.\n\np3 &lt;- cr_oromia |&gt; \n  ggplot(aes(x = sev2))+\n  geom_histogram()\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)"
  },
  {
    "objectID": "Aula5_quarto.html",
    "href": "Aula5_quarto.html",
    "title": "Análise exploratória 2",
    "section": "",
    "text": "No site R4PDE.net foi importado os dados denominados de pepper.\nEsse conjunto de dados fornece informações sobre a incidência de 3 epidemias diferentes na pimenta em função do tempo.\n\nlibrary(dplyr)\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \npepper\n\n# A tibble: 8 × 4\n      t   `1`   `2`   `3`\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0 0.08  0.001 0.001\n2     7 0.13  0.01  0.001\n3    14 0.78  0.09  0.01 \n4    21 0.92  0.25  0.05 \n5    28 0.99  0.8   0.18 \n6    35 0.995 0.98  0.34 \n7    42 0.999 0.99  0.48 \n8    49 0.999 0.999 0.74 \n\n\nVisualizando o conjunto de dados, pode-se perceber que eles estão no formato largo. Para que seja possível realizar uma análise exploratória desses dados, é necessário usar a função pivot_longer()do tidyverse para tranformar a tabela no formato longo.\n\nlibrary(tidyverse)\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\")\n\n# A tibble: 24 × 3\n       t epidemic   inc\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     0 1        0.08 \n 2     0 2        0.001\n 3     0 3        0.001\n 4     7 1        0.13 \n 5     7 2        0.01 \n 6     7 3        0.001\n 7    14 1        0.78 \n 8    14 2        0.09 \n 9    14 3        0.01 \n10    21 1        0.92 \n# ℹ 14 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nPara montagem dos gráficos, a tabela de dados deve estar no formato longo.\n\n\n\n\nPor ser um conjunto de dados com uma resposta numérica contínua em um fator temporal, esses dados foram transformados em um gráfico de linhas usando o geom_point()e o geom_line().\nPara atribuir um nome para cada linha formada, foi usada a função annotate().\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\",\n           x = 10,\n           y = 0.75,\n           label = \"1\")+\n  annotate(geom = \"text\",\n           x = 25,\n           y = 0.75,\n           label = \"2\")+\n  annotate(geom = \"text\",\n           x = 47,\n           y = 0.75,\n           label = \"3\")+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Aula5_quarto.html#trabalhando-com-gráfico-de-linha",
    "href": "Aula5_quarto.html#trabalhando-com-gráfico-de-linha",
    "title": "Análise exploratória 2",
    "section": "",
    "text": "Por ser um conjunto de dados com uma resposta numérica contínua em um fator temporal, esses dados foram transformados em um gráfico de linhas usando o geom_point()e o geom_line().\nPara atribuir um nome para cada linha formada, foi usada a função annotate().\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt; \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\",\n           x = 10,\n           y = 0.75,\n           label = \"1\")+\n  annotate(geom = \"text\",\n           x = 25,\n           y = 0.75,\n           label = \"2\")+\n  annotate(geom = \"text\",\n           x = 47,\n           y = 0.75,\n           label = \"3\")+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Aula5_quarto.html#trabalhando-com-gráfico-de-colunas",
    "href": "Aula5_quarto.html#trabalhando-com-gráfico-de-colunas",
    "title": "Análise exploratória 2",
    "section": "Trabalhando com gráfico de colunas",
    "text": "Trabalhando com gráfico de colunas\nSobre a contagem das formas de manejo das fazendas em função das cultivares, foi criado um gráfico de colunas usando a função geom_col(). O gráfico de colunas é bastante usado para representar valores numéricos associados a categorias.\nJunto ao gráfico, foi usado a função facet_wrap() para dividir os gráficos em função das cultivares.\n\nlibrary(ggthemes)\n\ncr |&gt; \n  count(farm_management, cultivar) |&gt; \n  ggplot(aes(cultivar, n, fill = farm_management, label = n))+\n  geom_col(position = \"dodge2\")+\n  scale_fill_canva()+\n  theme_bw()+\n  theme(strip.text.x = element_blank(),\n        legend.position = \"top\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")"
  },
  {
    "objectID": "Aula5_quarto.html#trabalhando-com-gráfico-errorbar",
    "href": "Aula5_quarto.html#trabalhando-com-gráfico-errorbar",
    "title": "Análise exploratória 2",
    "section": "Trabalhando com gráfico errorbar",
    "text": "Trabalhando com gráfico errorbar\nComo o conjunto de dados envolve um número grande de repetições, torna-se interessante realizar um gráfico de errorbar para demonstrar a faixa de variabilidade entre os valores.\nPara usar o geom_errobar(), é preciso primeiramente encontrar a média e o desvio padrão dos dados. Para isso pode ser utilizado a funçãogroup_by()para especificar otrate a funçãosummarize()para encontrar a média e desvio padrão. Tendo essas informações, pode-se criar um gráfico de barras com o error bar, usando ogeom_col()e ogeom_errobar().\n\nmg |&gt; \n  group_by(trat) |&gt; \n  summarise(mean_comp = mean(comp),\n            sd_comp = sd(comp)) |&gt; \n  ggplot(aes(trat, mean_comp))+\n  geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_point(size = 3)+\n  ylim(0, 20)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.1)+\n  annotate(geom = \"text\",  #Pode ser usado para mostrar que é estatisticamente diferente\n           x = 1,\n           y = 17.5,\n           label = \"*\")"
  },
  {
    "objectID": "Aula5_quarto.html#criando-subconjuntos-e-tabela-de-contingência",
    "href": "Aula5_quarto.html#criando-subconjuntos-e-tabela-de-contingência",
    "title": "Análise exploratória 2",
    "section": "Criando subconjuntos e tabela de contingência",
    "text": "Criando subconjuntos e tabela de contingência\nPara observar a quantidade e a frequência de nota de cada prova, foi separado os dados da prova 1 com os dados da prova 2, usando a função select() selecionando apenas as colunas prova e nota, e a função filter() separando a prova 1 da prova 2. Desse modo foi criado 2 subconjuntos de dados.\n\nnotas1 &lt;- notas |&gt; \n  select(prova, nota) |&gt; \n  filter(prova == \"1\")\nnotas1\n\n# A tibble: 22 × 2\n   prova  nota\n   &lt;dbl&gt; &lt;dbl&gt;\n 1     1  71.4\n 2     1  92.9\n 3     1  85.7\n 4     1  42.9\n 5     1 100  \n 6     1  85.7\n 7     1 100  \n 8     1  57.1\n 9     1 100  \n10     1  71.4\n# ℹ 12 more rows\n\nnotas2 &lt;- notas |&gt; \n  select(prova, nota) |&gt; \n  filter(prova == \"2\")\nnotas2\n\n# A tibble: 22 × 2\n   prova  nota\n   &lt;dbl&gt; &lt;dbl&gt;\n 1     2  81.2\n 2     2  68.8\n 3     2  87.5\n 4     2  87.5\n 5     2  87.5\n 6     2 100  \n 7     2 100  \n 8     2 100  \n 9     2 100  \n10     2  43.8\n# ℹ 12 more rows\n\n\nApós isso, foi usado a função count() dentro de cada subconjunto para contar a frequência de cada nota.\n\nnotas1 |&gt; \n  count(nota)\n\n# A tibble: 7 × 2\n   nota     n\n  &lt;dbl&gt; &lt;int&gt;\n1  42.9     2\n2  57.1     2\n3  64.3     2\n4  71.4     4\n5  85.7     3\n6  92.9     3\n7 100       6\n\nnotas2 |&gt; \n  count(nota)\n\n# A tibble: 6 × 2\n   nota     n\n  &lt;dbl&gt; &lt;int&gt;\n1  43.8     3\n2  56.2     1\n3  68.8     5\n4  81.2     2\n5  87.5     4\n6 100       7"
  },
  {
    "objectID": "Aula5_quarto.html#sumário-e-histograma",
    "href": "Aula5_quarto.html#sumário-e-histograma",
    "title": "Análise exploratória 2",
    "section": "Sumário e Histograma",
    "text": "Sumário e Histograma\nPara observar os dados sumarizados foi usado a função group_by() para agrupar os dados gerais em 2 grupos (prova 1 e prova 2), e depois foi usado a função summarise() para encontrar média, desvio padrão e mediana por prova, usando os argumentos mean(), sd() e median(), respectivamente.\n\nnotas |&gt; \n  group_by(prova) |&gt; \n  summarise(nota_mean = mean(nota),\n            nota_sd = sd(nota),\n            nota_med = median(nota))\n\n# A tibble: 2 × 4\n  prova nota_mean nota_sd nota_med\n  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1      79.5    19.0     85.7\n2     2      79.3    19.7     84.4\n\n\nPara a análise exploratória, foi realizado um histograma para cada prova, usando a função geom_histogram() para os subconjuntos criados. O histograma foi utilizado para demonstrar a distribuição de frequências. Após formados, os histogramas foram juntados em uma mesma imagem usando o pacote patchwork(). No histograma, para delimitar o número de colunas que aparecem no gráfico, foi usado o argumento bins = 5, e foi criado uma linha que marca a média dos dados usando a função geom_vline(). Para que os dois gráficos ficassem com o eixo Y padronizado, foi colocado ylim(0,10).\n\nmedia1 &lt;- mean(notas1$nota)\nmedia2 &lt;- mean(notas2$nota)\n\nlibrary(ggthemes)\np1 &lt;- notas1 |&gt; \n  ggplot(aes(x = nota))+\n  geom_histogram(bins = 5, fill = \"dark blue\", color = \"white\")+\n  geom_vline(xintercept = media1, color =\"red\", linetype = \"dashed\") +\n  scale_fill_canva()+\n  theme_bw(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  annotate(geom = \"text\",\n           x = 72,\n           y = 7.5,\n           label = \"Mean\")+\n  ylim(0,10)+\n  labs(y = \"Frequency\",\n       x = \"Notas\",\n       title = \"Prova 1\")\n\np2 &lt;- notas2 |&gt; \n  ggplot(aes(x = nota))+\n  geom_histogram(bins = 5, fill = \"orange\", color = \"white\")+\n  geom_vline(xintercept = media2, color =\"red\", linetype = \"dashed\") +\n  scale_fill_canva()+\n  theme_bw(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  annotate(geom = \"text\",\n           x = 72,\n           y = 6.5,\n           label = \"Mean\")+\n  ylim(0,10)+\n  labs(y = \"Frequency\",\n       x = \"Notas\",\n       title = \"Prova 2\")\n\nlibrary(patchwork)\n(p1 + p2) + \n  plot_layout(guides = \"collect\",\n              axes = \"collect\")\n\n\n\n\nAtravés da sumarização, pode-se observar que os valores médios das notas das duas provas são bem próximos, sendo 79.54 na prova 1 e 79.26 na prova 2. Pelo histograma também pode-se observar que na prova 1 a frequência de notas superiores a 90 foi maior do que o observado na prova 2, enquanto que na prova 2 a frequência de notas inferiores a 50 foi maior do que na prova 1."
  },
  {
    "objectID": "Aula5_quarto.html#trabalhando-com-boxplot",
    "href": "Aula5_quarto.html#trabalhando-com-boxplot",
    "title": "Análise exploratória 2",
    "section": "Trabalhando com Boxplot",
    "text": "Trabalhando com Boxplot\nUma outra análise exploratória que pode ser realizado é o boxplot, usando a função geom_boxplot(). Para que o gráfico considere as duas provas como diferentes, foi usado o factor() para que cada prova seja considerada como fator. Também foram adicionados os pontos usando geom_jitter(), que representa as notas tiradas em cada prova.\n\nnotas |&gt; \n  ggplot(aes(factor(prova), nota))+\n  geom_boxplot(fill = \"light blue\")+\n  geom_jitter(width = 0.05)+\n  labs(x = \"Notas\",\n       y = \"Prova\")\n\n\n\n\nNo boxplot pode-se observar que embora a prova 1 apresente a mediana um pouco maior que a prova 2, 50% das notas na prova 2 se encontram concentrados acima da nota 70, enquanto que 50% das notas na prova 1 se concentram abaixo da nota 100, mais ou menos entre 65 e 98."
  },
  {
    "objectID": "Aula5_quarto.html#trabalhando-com-gráfico-de-errobar",
    "href": "Aula5_quarto.html#trabalhando-com-gráfico-de-errobar",
    "title": "Análise exploratória 2",
    "section": "Trabalhando com gráfico de errobar",
    "text": "Trabalhando com gráfico de errobar\nPor último, também foi construído um gráfico de errobar usando as funções geom_point() e geom_errobar(). No qual o ponto médio representa a média de notas em cada prova e o errobar corresponde ao intervalo de confiança. Também foi definido um limite para o eixo Y usando o ylim(0,100).\n\nnotas |&gt; \n  group_by(prova) |&gt; \n  summarise(nota_mean = mean(nota),\n            nota_sd = sd(nota))|&gt; \n  ggplot(aes(factor(prova), nota_mean, color = prova))+\n  theme_few()+\n  theme(legend.position = \"none\")+\n  geom_point(size = 3)+  \n  geom_errorbar(aes(ymin = nota_mean - nota_sd,\n                    ymax = nota_mean + nota_sd),\n                width = 0.1)+\n  ylim(0,100)\n\n\n\n\nComo foi visto anteriormente na sumarização, os valores da média e desvio padrão foram bem semelhantes entre as duas provas, portanto não foi possível observar muita diferença através do gráfico de errobar."
  },
  {
    "objectID": "Aula6_quarto.html",
    "href": "Aula6_quarto.html",
    "title": "Teste-t",
    "section": "",
    "text": "Diferentemente da estatística descritiva, a estatística inferencial dedica-se à extrapolação de conclusões acerca de uma população maior, baseando-se em uma amostra de dados.\nEste ramo utiliza métodos estatísticos para testar hipóteses e estimar parâmetros, possibilitando inferências sobre características da população a partir da análise de amostras.\nTestes de Hipóteses: Os testes de hipóteses são procedimentos que permitem tomar decisões sobre a população com base em amostras de dados. Utilizam-se para determinar se um resultado observado em dados de amostra pode ser atribuído ao acaso ou se é estatisticamente significativo.\nP-Valor (Valor de Probabilidade): O valor de p é uma medida que indica a probabilidade de observar os resultados encontrados, ou resultados mais extremos, sob a suposição de que a hipótese nula é verdadeira. Valores de p baixos (tipicamente menor que 0,05) sugerem que é improvável obter tais resultados por acaso, levando à rejeição da hipótese nula.\nA principal diferença entre a estatística descritiva e estatística inferencial mais notável entre estes dois ramos reside na abordagem dos dados: enquanto a Estatística Descritiva concentra-se na descrição e síntese das características dos dados coletados, a Estatística Inferencial ocupa-se com a generalização dessas observações para populações maiores, permitindo a formulação de inferências e previsões."
  },
  {
    "objectID": "Aula6_quarto.html#importação-de-dados",
    "href": "Aula6_quarto.html#importação-de-dados",
    "title": "Teste-t",
    "section": "Importação de dados",
    "text": "Importação de dados\nO conjunto de dados foi importado do Google Sheet usando a função gsheet2tbl() do pacote gsheet. Nesse conjunto existem dois grupos independentes: um grupo de plantas em que foi aplicado Mg2 e um grupo de plantas controle (sem aplicação).\n\nlibrary(gsheet)\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\nmg\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\n\nPodemos observar que o conjunto de dados está no formato longo. Para o teste-t, é preciso que os dados estejam no formato largo, portanto eles serão transformados através da função pivot_wider().\n\nlibrary(tidyr)\nlibrary(tidyverse)\n\nmg2 &lt;- mg |&gt; \n  pivot_wider(names_from = trat,\n              values_from = comp)"
  },
  {
    "objectID": "Aula6_quarto.html#visualização-dos-dados",
    "href": "Aula6_quarto.html#visualização-dos-dados",
    "title": "Teste-t",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nO conjunto de dados pode ser visualizado por meio de um boxplot, criado através da função ggplot() juntamente a geom_boxplot().\n\nmg |&gt; \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n\n\n\n\nAtravés do boxplot é possível assumir visualmente que os grupos seguem uma distribuição normal (pela simetria do boxplot formado) e que possuem variância homogênea (a estrutura dos dois boxplot são similares), mas os testes de premissas ainda devem ser feitos para confirmar."
  },
  {
    "objectID": "Aula6_quarto.html#teste-de-premissas",
    "href": "Aula6_quarto.html#teste-de-premissas",
    "title": "Teste-t",
    "section": "Teste de premissas",
    "text": "Teste de premissas\nPara avaliar se o conjunto de dados segue uma distribuição normal, é preciso ser feito o Shapiro-test para cada um dos grupos. Esse teste pode ser realizada usando a função shapiro.test(). A função hist() também pode ser utilizada para observar visualmente se a distribuição dos dados é normal ou não.\nComo qualquer outro teste estatístico, o Shapiro-test também formula hipótese nula e alternativa. A Hipótese nula (Ho) é que a distribuição do conjunto de dados segue uma distribuição normal, enquanto que a Hipótese alternativa (Ha) diz que a distribuição dos dados não segue uma distribuição normal.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nhist(mg2$control)\n\n\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\nhist(mg2$Mg2)\n\n\n\n\nObserva-se que em ambos os grupos o p-valor é superior ao nível de significância de 5%, portanto não se rejeita a hipótese nula e a distribuição pode ser considerada normal.\nOutra forma visual de verificar a normalidade dos dados do grupo é através das funções qqnorm() e qqline(). Conforme os pontos são mais próximos à reta, mais os dados seguem a normalidade.\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n\n\n\n\nPara verificar se as variâncias dos dois grupos são homogêneas, pode ser utilizado a função var.test(). Do mesmo modo, a Hipótese nula (Ho) diz que as variâncias entre os dois grupos são homogêneas, enquanto que a Hipótese alternativa (Ha) diz que as variâncias não são homogêneas.\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nO p-valor foi maior que o nível de significância (5%), portanto não se rejeita a hipótese nula que as variâncias são homogêneas."
  },
  {
    "objectID": "Aula6_quarto.html#teste-de-hipótese",
    "href": "Aula6_quarto.html#teste-de-hipótese",
    "title": "Teste-t",
    "section": "Teste de Hipótese",
    "text": "Teste de Hipótese\nVisto que as premissas foram atendidas, o próximo passo é o teste de hipótese propriamente dito. O teste-t é executado através da função t.test(), no qual devem ser especificados os dois grupos que serão analisados.\n\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\nteste1\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\nObserva-se que o p-valor foi muito inferior ao nível de significância de 5%, rejeitando a hipótese nula de que as médias entre os dois grupos são iguais. Logo, pode-se concluir que os dois grupos diferem estatisticamente um do outro.\nCaso as variâncias entre os dois grupos fossem heterogêneas, poderia ser adicionado o argumento var.equal = FALSE no teste-t.\nUsando a função report() do pacote report, um resumo da análise é montada automaticamente.\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])"
  },
  {
    "objectID": "Aula6_quarto.html#importação-dos-dados",
    "href": "Aula6_quarto.html#importação-dos-dados",
    "title": "Teste-t",
    "section": "Importação dos dados",
    "text": "Importação dos dados\nO conjunto de dados foi importado do Google Sheet usando a função gsheet2tbl() do pacote gsheet. Nesse conjunto existem dois grupos dependentes: avaliações realizadas sem ajuda de um instrumento e avaliações realizadas com ajuda de um instrumento sobre o mesmo conjunto de indivíduos.\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nA função pivot_wider() foi usada para transformar o conjunto de dados de formato longo para formato largo.\n\nescala2 &lt;- escala |&gt; \n  select(assessment, rater, acuracia) |&gt; \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)"
  },
  {
    "objectID": "Aula6_quarto.html#visualização-dos-dados-1",
    "href": "Aula6_quarto.html#visualização-dos-dados-1",
    "title": "Teste-t",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nA visualização dos dados foi feita com as funções ggplot() e geom_boxplot().\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n\nApenas pelo gráfico é possível observar que a estutura dos dois grupos é diferente um do outro, podendo indicar variâncias heterogêneas."
  },
  {
    "objectID": "Aula6_quarto.html#teste-de-premissas-1",
    "href": "Aula6_quarto.html#teste-de-premissas-1",
    "title": "Teste-t",
    "section": "Teste de premissas",
    "text": "Teste de premissas\nFoi usada a função shapiro.test() para cada grupo para determinar se eles seguem normalidade ou não.\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n#Em ambos os testes de normalidade, não rejeitamos a hipótese nula --&gt; tem distribuição normal\n\nEm ambos os testes, o p-valor foi inferior ao nível de significância, indicando que a hipótese nula deve ser rejeitada e que os conjuntos de dados não seguem uma distribuição normal.\nEm seguida foi realizado o teste de variância pela função var.test().\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nNovamente o p-valor foi inferior a 5%, indicando que as variâncias são heterogêneas."
  },
  {
    "objectID": "Aula6_quarto.html#teste-de-hipótese-1",
    "href": "Aula6_quarto.html#teste-de-hipótese-1",
    "title": "Teste-t",
    "section": "Teste de Hipótese",
    "text": "Teste de Hipótese\nPara este caso de conjunto de dados onde os dois grupos são dependentes e apresentam variâncias heterogêneas, o teste-t é realizado com a função t.test() usando os argumentos paired = TRUE e var.equal = FALSE.\n\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n\nComo o p-valor foi inferior ao nível de significância, rejeitamos a hipótese nula de que os dois grupos são iguais."
  },
  {
    "objectID": "Aula6_quarto.html#teste-de-premissas-2",
    "href": "Aula6_quarto.html#teste-de-premissas-2",
    "title": "Teste-t",
    "section": "Teste de premissas",
    "text": "Teste de premissas\nUsando o mesmo conjunto de dados da análise anterior, observa-se que nem a premissa de normalidade e nem a premissa de homocedasticidade foram atendidas.\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nvar.test(escala2$Aided1, escala2$Unaided)\n\n\n    F test to compare two variances\n\ndata:  escala2$Aided1 and escala2$Unaided\nF = 0.047668, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.01184004 0.19191079\nsample estimates:\nratio of variances \n        0.04766793"
  },
  {
    "objectID": "Aula6_quarto.html#teste-de-hipótese-2",
    "href": "Aula6_quarto.html#teste-de-hipótese-2",
    "title": "Teste-t",
    "section": "Teste de Hipótese",
    "text": "Teste de Hipótese\nComo o conjunto de dados não apresenta uma distribuição normal, não tem variâncias homogêneas e envolve dois grupos dependentes, será aplicado o teste de Wilcoxon através da função wilcox.test(), usando o argumento paired = TRUE.\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\nObserva-se que o p-valor é inferior ao nível de significância, indicando que a hipótese nula de que os dois grupos são iguais é rejeitada."
  },
  {
    "objectID": "Aula7_quarto.html",
    "href": "Aula7_quarto.html",
    "title": "ANOVA",
    "section": "",
    "text": "A Análise de Variância (ou ANOVA) é uma técnica estatística usada para comparar a média de três ou mais grupos e determinar se há diferenças significativas entre eles.\nNo caso da ANOVA, as hipóteses formuladas são as seguintes: - Hipótese nula (Ho): as médias dos grupos não diferem entre si - Hipótese alternativa (Ha): pelo menos a média de um dos grupos difere das demais\nQuando o conjunto de dados apresenta um único fator, a análise de variância realizada é denominada de One-Way ANOVA ou ANOVA unifatorial.\nQuando o conjunto de dados apresenta dois fatores, a análise de variância realizada é denominada de Two-Way ANOVA ou ANOVA fatorial.\n\n\nUsando a função gsheet2tbl() do pacote gsheet, foi importado um conjunto de dados envolvendo 5 grupos independentes.\n\nlibrary(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\n\n\nPara a visualização dos dados, foi usada a função ggplot() juntamente com o geom_jitter(). Como o conjunto de dados possui apenas 6 repetições para cada grupo, é preferível usar o jitter que o boxplot.\n\nlibrary(tidyverse)\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.05)\n\n\n\n\nPode-se observar que há uma variabilidade visível entre os diferentes grupos, podendo inferir que uma das médias será diferente das demais.\n\n\n\nPara executar uma análise de variância com o conjunto de dados trabalhado, o primeiro passo é ajustar os dados em um modelo linear. Esse ajuste é realiza através da função lm(), no qual a fórmula tcm ~ especie especifica que tcm (a variável resposta) está sendo modelada em função de especie (a variável preditora).\n\nm1 &lt;- lm(tcm ~ especie, data = micelial)\n\nPara exibir um resumo detalhado do modelo ajustado, pode ser utilizada a função summary(). Ela fornece as seguintes informações: - Coeficientes: Estimativas dos parâmetros do modelo (intercepto e coeficientes para cada nível de especie). - Erro padrão: Medida da precisão das estimativas dos coeficientes. - Estatística t e valor p: Usados para testar a hipótese nula de que cada coeficiente é igual a zero (sem efeito). - R^2 e R^2 ajustado: Medidas da qualidade do ajuste do modelo aos dados. - Estatística F: Teste global de significância do modelo.\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n#Se quisermos fazer o summary sem interceptar uma espécie:\nm2 &lt;- lm(tcm ~ especie -1, data = micelial)\nsummary(m2)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n\nPor fim, a análise de variância é executada usando a função anova(). Ela fornece as seguintes informações: - Df: Graus de liberdade associados ao modelo e aos resíduos. - Sum Sq: Soma dos quadrados (Soma dos quadrados do modelo e dos resíduos). - Mean Sq: Quadrados médios (Soma dos quadrados dividida pelos graus de liberdade correspondentes). - F value: Estatística F (razão dos quadrados médios do modelo e dos resíduos). - Pr(&gt;F): Valor p associado à estatística F, usado para testar a hipótese nula de que todos os coeficientes (exceto o intercepto) são iguais a zero.\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo o p-valor foi inferior ao nível de significância (5%), podemos rejeitar a hipótese nula de que todos os grupos são iguais. Logo, pelo menos uma das médias difere estatisticamente das demais.\nContudo, através da ANOVA não é possível saber qual dos grupos difere das demais ou se há mais de um grupo que difere estatisticamente.\n\n\n\nPara saber qual média está se diferindo das demais, deve ser utilizado um teste de comparação de médias, como o Teste de Tukey.\nPara realizar esse teste, primeiramente foi usada a função emmeans() do pacote emmeans para obter as médias da variável resposta em função das espécies (grupos).\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\nmedias1\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\n\nUsando a função cld() e argumento Letters = letters dos pacotes multcompe multcompView, é possível visualizar a diferença entre os grupos através do agrupamento das médias estatisticamente iguais representadas pela mesma letra.\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias1, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObservando o resultado do Teste de Tukey, ocorreu a formação de 3 grupos estatisticamente distintos. Pode-se inferir que a espécie Fgra difere estatisticamente de todas as outras espécies. A espécie Fasi só não difere estatisticamente da espécie Fmer. As espécies Faus e Fcor não diferem entre si e não diferem de Fmer, mas diferem do resto das espécies.\n\n\n\nNa Análise de Variância, as premissas de normalidade e de homocedasticidade também devem ser atendidas.\nO teste de normalidade nesse caso é feito com os residuals (é cada diferença entre a média estimada e o valor original).\n\nhist(m1$residuals)\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\n\nObserva-se que não rejeita a hipótese nula, ou seja, os dados são normais.\nO teste de variância para três ou mais grupos independentes é feito com o Bartlett-test. Ele é executado usando a função bartlett.test().\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n#Não rejeita a hipótese nula --&gt; são homogêneas\n\nNota-se que a hipótese nula não é rejeitada, indicando que as variâncias são homogêneas.\n\n\nOutra forma de checar se as premissas foram atendidas é através da função simulateResiduals() do pacote DHARMa.\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\nO gráfico da esquerda é um QQ plot dos residuals, ele compara a distribuição dos resíduos simulados com a distribuição teórica esperada (geralmente a normal). Os pontos devem seguir a linha diagonal. Desvios significativos da linha indicam que os resíduos não seguem a distribuição esperada, sugerindo que o modelo pode estar mal ajustado. Nesse caso não foi observado nenhum desvio.\nO gráfico da direita mostra os resíduos simulados em função dos valores preditos pelo modelo. Para que a premissa da homocedasticidade seja atendida, não deve haver nenhum padrão evidente. Padrões ou tendências podem indicar falta de ajuste, variância não constante ou relações não modeladas entre as variáveis.\n\n\n\nOutra forma de checar as premissas é através das funções check_normality() e check_heteroscedasticity() do pacote performance. Eles conferem se os dados apresentam distribuição normal e variâncias homogêneas de forma automática.\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880)."
  },
  {
    "objectID": "Aula7_quarto.html#importação-dos-dados",
    "href": "Aula7_quarto.html#importação-dos-dados",
    "title": "ANOVA",
    "section": "",
    "text": "Usando a função gsheet2tbl() do pacote gsheet, foi importado um conjunto de dados envolvendo 5 grupos independentes.\n\nlibrary(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")"
  },
  {
    "objectID": "Aula7_quarto.html#visualização-dos-dados",
    "href": "Aula7_quarto.html#visualização-dos-dados",
    "title": "ANOVA",
    "section": "",
    "text": "Para a visualização dos dados, foi usada a função ggplot() juntamente com o geom_jitter(). Como o conjunto de dados possui apenas 6 repetições para cada grupo, é preferível usar o jitter que o boxplot.\n\nlibrary(tidyverse)\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.05)\n\n\n\n\nPode-se observar que há uma variabilidade visível entre os diferentes grupos, podendo inferir que uma das médias será diferente das demais."
  },
  {
    "objectID": "Aula7_quarto.html#anova",
    "href": "Aula7_quarto.html#anova",
    "title": "ANOVA",
    "section": "",
    "text": "Para executar uma análise de variância com o conjunto de dados trabalhado, o primeiro passo é ajustar os dados em um modelo linear. Esse ajuste é realiza através da função lm(), no qual a fórmula tcm ~ especie especifica que tcm (a variável resposta) está sendo modelada em função de especie (a variável preditora).\n\nm1 &lt;- lm(tcm ~ especie, data = micelial)\n\nPara exibir um resumo detalhado do modelo ajustado, pode ser utilizada a função summary(). Ela fornece as seguintes informações: - Coeficientes: Estimativas dos parâmetros do modelo (intercepto e coeficientes para cada nível de especie). - Erro padrão: Medida da precisão das estimativas dos coeficientes. - Estatística t e valor p: Usados para testar a hipótese nula de que cada coeficiente é igual a zero (sem efeito). - R^2 e R^2 ajustado: Medidas da qualidade do ajuste do modelo aos dados. - Estatística F: Teste global de significância do modelo.\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n#Se quisermos fazer o summary sem interceptar uma espécie:\nm2 &lt;- lm(tcm ~ especie -1, data = micelial)\nsummary(m2)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\n\nPor fim, a análise de variância é executada usando a função anova(). Ela fornece as seguintes informações: - Df: Graus de liberdade associados ao modelo e aos resíduos. - Sum Sq: Soma dos quadrados (Soma dos quadrados do modelo e dos resíduos). - Mean Sq: Quadrados médios (Soma dos quadrados dividida pelos graus de liberdade correspondentes). - F value: Estatística F (razão dos quadrados médios do modelo e dos resíduos). - Pr(&gt;F): Valor p associado à estatística F, usado para testar a hipótese nula de que todos os coeficientes (exceto o intercepto) são iguais a zero.\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo o p-valor foi inferior ao nível de significância (5%), podemos rejeitar a hipótese nula de que todos os grupos são iguais. Logo, pelo menos uma das médias difere estatisticamente das demais.\nContudo, através da ANOVA não é possível saber qual dos grupos difere das demais ou se há mais de um grupo que difere estatisticamente."
  },
  {
    "objectID": "Aula7_quarto.html#teste-de-tukey",
    "href": "Aula7_quarto.html#teste-de-tukey",
    "title": "ANOVA",
    "section": "",
    "text": "Para saber qual média está se diferindo das demais, deve ser utilizado um teste de comparação de médias, como o Teste de Tukey.\nPara realizar esse teste, primeiramente foi usada a função emmeans() do pacote emmeans para obter as médias da variável resposta em função das espécies (grupos).\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\nmedias1\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\n\nUsando a função cld() e argumento Letters = letters dos pacotes multcompe multcompView, é possível visualizar a diferença entre os grupos através do agrupamento das médias estatisticamente iguais representadas pela mesma letra.\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias1, Letters = letters)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  a    \n Faus     1.237 0.0559 25    1.122     1.35   b   \n Fcor     1.322 0.0559 25    1.207     1.44   b   \n Fmer     1.427 0.0559 25    1.312     1.54   bc  \n Fasi     1.572 0.0559 25    1.457     1.69    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObservando o resultado do Teste de Tukey, ocorreu a formação de 3 grupos estatisticamente distintos. Pode-se inferir que a espécie Fgra difere estatisticamente de todas as outras espécies. A espécie Fasi só não difere estatisticamente da espécie Fmer. As espécies Faus e Fcor não diferem entre si e não diferem de Fmer, mas diferem do resto das espécies."
  },
  {
    "objectID": "Aula7_quarto.html#teste-das-premissas",
    "href": "Aula7_quarto.html#teste-das-premissas",
    "title": "ANOVA",
    "section": "",
    "text": "Na Análise de Variância, as premissas de normalidade e de homocedasticidade também devem ser atendidas.\nO teste de normalidade nesse caso é feito com os residuals (é cada diferença entre a média estimada e o valor original).\n\nhist(m1$residuals)\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\n\nObserva-se que não rejeita a hipótese nula, ou seja, os dados são normais.\nO teste de variância para três ou mais grupos independentes é feito com o Bartlett-test. Ele é executado usando a função bartlett.test().\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n#Não rejeita a hipótese nula --&gt; são homogêneas\n\nNota-se que a hipótese nula não é rejeitada, indicando que as variâncias são homogêneas.\n\n\nOutra forma de checar se as premissas foram atendidas é através da função simulateResiduals() do pacote DHARMa.\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\nO gráfico da esquerda é um QQ plot dos residuals, ele compara a distribuição dos resíduos simulados com a distribuição teórica esperada (geralmente a normal). Os pontos devem seguir a linha diagonal. Desvios significativos da linha indicam que os resíduos não seguem a distribuição esperada, sugerindo que o modelo pode estar mal ajustado. Nesse caso não foi observado nenhum desvio.\nO gráfico da direita mostra os resíduos simulados em função dos valores preditos pelo modelo. Para que a premissa da homocedasticidade seja atendida, não deve haver nenhum padrão evidente. Padrões ou tendências podem indicar falta de ajuste, variância não constante ou relações não modeladas entre as variáveis.\n\n\n\nOutra forma de checar as premissas é através das funções check_normality() e check_heteroscedasticity() do pacote performance. Eles conferem se os dados apresentam distribuição normal e variâncias homogêneas de forma automática.\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880)."
  },
  {
    "objectID": "Aula7_quarto.html#importação-dos-dados-1",
    "href": "Aula7_quarto.html#importação-dos-dados-1",
    "title": "ANOVA",
    "section": "Importação dos dados",
    "text": "Importação dos dados\nFoi importando um dataframe nativo do R, denominado de InsectSprays.\n\ninseticida &lt;- InsectSprays\n\nPara contar quantos inseticidas diferentes foram usados, foi executado a função count().\n\ninseticida |&gt; \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12"
  },
  {
    "objectID": "Aula7_quarto.html#visualização-dos-dados-1",
    "href": "Aula7_quarto.html#visualização-dos-dados-1",
    "title": "ANOVA",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nPara visualizar os dados, foi criado um gráfico de boxplot e de pontos usando as funções ggplot(), geom_boxplot() e geom_jitter().\n\ninseticida |&gt; \n  ggplot(aes(spray, count))+\n  geom_jitter(width = 0.05)+\n  geom_boxplot()\n\n\n\n\nPela assimetria dos boxplots e pela suas estruturas, já é possível prever que o conjunto de dados não atende as premissas de normalidade e homocedasticidade."
  },
  {
    "objectID": "Aula7_quarto.html#anova-1",
    "href": "Aula7_quarto.html#anova-1",
    "title": "ANOVA",
    "section": "ANOVA",
    "text": "ANOVA\nPara realizar a análise de variância, os dados foram ajustado ao modelo linear pela função lm() e foi executado a anova().\n\nm2 &lt;- lm(count ~ spray, data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCom o p-valor inferior ao nível de significância, a hipótese nula é rejeitada."
  },
  {
    "objectID": "Aula7_quarto.html#teste-de-tukey-1",
    "href": "Aula7_quarto.html#teste-de-tukey-1",
    "title": "ANOVA",
    "section": "Teste de Tukey",
    "text": "Teste de Tukey\nEm seguida foi usado o Teste de Tukey para comparação das médias entre os grupos\n\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\ncld(m2_medias, Letters = letters)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  a    \n E       3.50 1.13 66    1.240     5.76  a    \n D       4.92 1.13 66    2.656     7.18  a    \n A      14.50 1.13 66   12.240    16.76   b   \n B      15.33 1.13 66   13.073    17.59   b   \n F      16.67 1.13 66   14.406    18.93   b   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nPelo resultado do teste nota-se que existem dois grupos estatisticamente diferentes. Sendo que os inseticidas C, E e D não diferem entre si, mas diferem de A, B e F (que por sua vez não diferem entre si).\nTanto a Análise de Variância quanto o Teste de Tukey foram executados, no entanto, para que essas análises sejam considerados válidos, é necessário conferir se o conjunto de dados atende às premissas de normalidade e de homocedasticidade."
  },
  {
    "objectID": "Aula7_quarto.html#teste-de-normalidade",
    "href": "Aula7_quarto.html#teste-de-normalidade",
    "title": "ANOVA",
    "section": "Teste de normalidade",
    "text": "Teste de normalidade\nO teste de normalidade foi executado por meio do Shapiro-test com os resíduos através da função shapiro.test(). Também foi usado qqnorm() e qqline() para visualizar a normalidade por meio de gráfico.\n\nhist(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.96006, p-value = 0.02226\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\nO Shapiro-test forneceu um p-valor inferior ao nível de significância, rejeitando a hipótese nula de que o dado segue uma distribuição normal, ou seja, os dados não apresentam normalidade.\nO gráfico criado também demonstra desvios em relação à reta, o que indica a não normalidade."
  },
  {
    "objectID": "Aula7_quarto.html#teste-de-variância",
    "href": "Aula7_quarto.html#teste-de-variância",
    "title": "ANOVA",
    "section": "Teste de variância",
    "text": "Teste de variância\nO teste de variância foi executado com a função bartlett.test().\n\nbartlett.test(count ~ spray, data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n#Rejeitamos a homogeneicidade entre as variâncias\n\nObserva-se que o p-valor é inferior a 5%, rejeitando a hipótese nula de que as variâncias são homogêneas.\nUsando as funções check_normality() e check_heteroscedasticity(), observa-se os mesmos resultados.\n\ncheck_normality(m2)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nA função simulateResiduals() também indica a falta de homocedasticidade dos dados, embora não indique a falta de normalidade.\n\nplot(simulateResiduals(m2))\n\n\n\n\nNão atendendo as duas premissas, esse conjunto de dados precisa ser manipulado para que as premissas sejam atendidas e o resultado de sua análise seja válido."
  },
  {
    "objectID": "Aula7_quarto.html#alternativa-1---transformação-de-dados",
    "href": "Aula7_quarto.html#alternativa-1---transformação-de-dados",
    "title": "ANOVA",
    "section": "Alternativa 1 - Transformação de dados",
    "text": "Alternativa 1 - Transformação de dados\nUma medida que pode ser adotada para que os dados atendam as premissas é a transformação dos dados.\nOs dados podem ser transformados de diversas formas, mas os principais são por raiz quadrada, por log(x) e por box-cox.\n\n\n\n\n\n\nNote\n\n\n\nPode ser usado log(x + 0.5) ao invés de log(x) quando existe um valor igual a 0 nas variáveis respostas.\n\n\n\nTransformação por raiz quadrada\nUma nova coluna com os valores transformados será criado para o conjunto de dados usando a função mutate().\n\ninseticida &lt;- inseticida |&gt; \n  mutate(count2 = sqrt(count))\n\nVisualizando os novos dados, é possível notar as alterações.\n\ninseticida |&gt; \n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\nCom os dados transformados, será realizado uma nova análise de variância para observar se houve alguma mudança.\n\nm3 &lt;- lm(count2 ~ spray,\n         data = inseticida)\nsummary(m3)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m3)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA análise continua rejeitando a hipótese nula. Em seguida foi comparado as médias entre os grupos.\n\nm3_medias &lt;- emmeans(m3, ~ spray)\nplot(m3_medias)\n\n\n\ncld(m3_medias, Letters = letters) #Os dados transformados discriminou melhor, separou mais\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  a    \n E       1.81 0.181 66    1.447     2.17  ab   \n D       2.16 0.181 66    1.802     2.53   b   \n A       3.76 0.181 66    3.399     4.12    c  \n B       3.88 0.181 66    3.514     4.24    c  \n F       4.02 0.181 66    3.656     4.38    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se que dessa vez foram criados 3 grupos estatisticamente distintos, o que significa que os dados transformados discriminou melhor os grupos.\nOutra forma de observar a comparação das médias entre grupos é pela função pwpm(), que permite a comparação entre cada grupo, um por um. A função pwpp() mostra a comparação entre grupos através de um gráfico. A função pairs() compara os grupos par por par.\n\npwpm(m3_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m3_medias)\n\n\n\npairs(m3_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\nAs premissas são conferidas novamente para observar se houve mudança com a transformação dos dados.\n\nhist(m3$residuals)\n\n\n\nqqnorm(m3$residuals)\nqqline(m3$residuals)\n\n\n\nshapiro.test(m3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m3$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\ncheck_normality(m3)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m3)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nplot(simulateResiduals(m3))\n\n\n\n\nAs duas premissas foram atendidas, dando validade à análise de variância realizada.\n\n\nTransformação por Box-cox\nOutra forma de transformar os dados é através do Box-cox. Para essa transformação, é preciso encontrar o valor de lambda (\\(\\lambda\\)), extraído a partir da função boxcox() do pacote MASS. Essa função calcula a verossimilhança perfilhada do parâmetro \\(\\lambda\\). Devemos escolher o valor que maximiza esta função.\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~ 1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\nEncontrado o valor de \\(\\lambda\\), uma nova coluna será adicionada ao conjunto de dados com os novos dados transformados.\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1)/ lambda\ninseticida$count3\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\n\nDepois de transformados, devem ser realizados os mesmos passos da análise de variância com os novos dados."
  },
  {
    "objectID": "Aula7_quarto.html#alternativa-2---não-paramétrico",
    "href": "Aula7_quarto.html#alternativa-2---não-paramétrico",
    "title": "ANOVA",
    "section": "Alternativa 2 - Não paramétrico",
    "text": "Alternativa 2 - Não paramétrico\nOutra alternativa para se trabalhar com dados que não atendem as premissas é realizando um teste não-paramétrico. Dessa forma é analisado os dados originais, sem passar por transformação.\nA alternativa não-paramétrica para a ANOVA é o teste de Kruscal-Wallis. O teste de Kruscal-Wallis é o teste não paramétrico utilizado na comparação de três ou mais amostras independentes. Ele nos indica se há diferença entre pelo menos dois deles. A aplicação do teste utiliza os valores numéricos transformados em postos (rankings) e agrupados num só conjunto de dados. A comparação dos grupos é realizada por meio da média dos postos (posto médio).\nPara executar esse teste, é necessário utiliza a função kruskal.test() do pacote agricolae.\n\nlibrary(agricolae)\nkruskal.test(count ~ spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n\nObserva-se que o p-valor foi inferior ao nível de significância, rejeitando a hipótese nula de que os grupos são iguais.\nA comparação da média entre os grupos também pode ser realizado usando a função kruskal() e o argumento group = TRUE.\n\nm4 &lt;- kruskal(inseticida$count, \n              inseticida$spray, \n              group = TRUE)\nm4\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\nNota-se que os grupos formados são o mesmo da alternativa 1."
  },
  {
    "objectID": "Aula7_quarto.html#alternativa-3---glms",
    "href": "Aula7_quarto.html#alternativa-3---glms",
    "title": "ANOVA",
    "section": "Alternativa 3 - GLMs",
    "text": "Alternativa 3 - GLMs\nOs modelos lineares generalizados (GLMs) são uma ampliação dos modelos lineares ordinários. Os GLM’s são usados quando os resíduos (erro) do modelo apresentam distribuição diferente da normal (gaussiana).\nNo GLMs, deve-se especificar a distribuição de frequência que deseja utilizar para modelar a variável resposta. Esta distribuição de frequência deve pertencer à família exponencial, que inclui a distribuição de Poisson, Gaussiana, Binomial, Binomial negativa, Gamma, Bernoulli e Beta.\nSe Y é uma variável contínua, a sua distribuição de probabilidade deve ser normal. Nesses casos as distribuições recomendadas são a Gaussiana (Normal) ou Gamma. Se Y é uma variável de proporção que varia continuamente entre 0 e 1 ou 0 e 100, mas não inclui 0 nem 1, a distribuição recomendada é a Beta.\nSe Y é binário (e.g., vivo ou morto), a distribuição de probabilidade deve ser Binomial. Se Y é uma contagem (e.g., abundância ou riqueza de espécies), então a distribuição de probabilidade deve ser Poisson ou Binomial Negativa.\nNo caso do conjunto de dados trabalhado, a variável Y representa uma contagem, o que permite utilizar a família Poisson. Para executar o ajuste do modelo, é utilizado a função glm() com o argumento family = poisson.\nTendo o modelo ajustado, são repetidos os mesmos passos de uma análise de variância normal. A única diferença é que ao invés de usar a função anova(), recomenda-se usar a função Anova() do pacote car, pois ele fornece diretamente o p-valor.\n\nm5 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\nsummary(m5)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m5)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\nlibrary(car)\nAnova(m5)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObserva-se que o p-valor foi inferior ao nível de significância, rejeitando a hipótese nula de que os grupos são iguais.\nAs premissas podem ser conferidas através da função simulateResiduals().\n\nplot(simulateResiduals(m5))\n\n\n\n\nEmbora a normalidade não foi atendida, a premissa da homocedasticidade tem maior peso.\nO teste de comparação das médias foi executado através do emmeans() e cld().\n\nm5_medias &lt;- emmeans(m5, ~ spray,\n                     type = \"response\")\nm5_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\ncld(m5_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAs 3 alternativas deram o mesmo resultado, mas o GLMs é o mais utilizado pelo fato dele não precisar transformar os dados de maneira nenhuma e permitir o uso da ANOVA."
  },
  {
    "objectID": "Aula7_quarto.html#importação-dos-dados-2",
    "href": "Aula7_quarto.html#importação-dos-dados-2",
    "title": "ANOVA",
    "section": "Importação dos dados",
    "text": "Importação dos dados\nOs dados foram importados do Google Sheets pela função gsheet2tbl() do pacote gsheet. O conjunto de dados avalia a severidade de uma doença em função de dois fatores: o tipo de tratamento aplicado e as doses do tratamento.\n\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\nli\n\n# A tibble: 20 × 8\n   treat         dose   rep  n_sp dis_sp n_seeds inf_seeds severity\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Ionic liquid   0.5     1   103     13      25        10   0.126 \n 2 Ionic liquid   0.5     2   125     31      25        12   0.248 \n 3 Ionic liquid   0.5     3   210     80      25        12   0.381 \n 4 Ionic liquid   0.5     4    97     28      25        10   0.289 \n 5 Ionic liquid   0.5     5   180     75      25        11   0.417 \n 6 Ionic liquid   2       2   116      9      25         6   0.0776\n 7 Ionic liquid   2       3   166      7      25         3   0.0422\n 8 Ionic liquid   2       4   157     12      25         1   0.0764\n 9 Ionic liquid   2       5   129      7      25         7   0.0543\n10 Ionic liquid   2       1    84      0      25         1   0     \n11 Tebuconazole   0.5     1   121      0      25         2   0     \n12 Tebuconazole   0.5     2   123      6      25         5   0.0488\n13 Tebuconazole   0.5     3   107      3      25         1   0.0280\n14 Tebuconazole   0.5     4    90      0      25         2   0     \n15 Tebuconazole   0.5     5   142      4      25         1   0.0282\n16 Tebuconazole   2       1   166      3      25         5   0.0181\n17 Tebuconazole   2       2   120      0      25         2   0     \n18 Tebuconazole   2       3   100      4      25         2   0.04  \n19 Tebuconazole   2       4    96      3      25         0   0.0312\n20 Tebuconazole   2       5   170      2      25         4   0.0118"
  },
  {
    "objectID": "Aula7_quarto.html#visualização-dos-dados-2",
    "href": "Aula7_quarto.html#visualização-dos-dados-2",
    "title": "ANOVA",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nComo o número de repetições é baixo, o conjunto de dados será visualizado com um gráfico de pontos usando a função ggplot() juntamente a geom_jitter(). A função facet_wrap() foi usada para dividir os dados em função do tratamento aplicado.\n\nlibrary(ggthemes)\nli |&gt; \n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~treat)+\n  theme_bw()"
  },
  {
    "objectID": "Aula7_quarto.html#modelo-fatorial-2-way-anova",
    "href": "Aula7_quarto.html#modelo-fatorial-2-way-anova",
    "title": "ANOVA",
    "section": "Modelo fatorial (2-way ANOVA)",
    "text": "Modelo fatorial (2-way ANOVA)\nA função utilizada para o ajuste do modelo linear é a mesma: lm(). No entanto, como se trata de dois fatores envolvidos (treat e dose), a fórmula usada é severity ~ treat*factor(dose). O grupo dose foi especificado como um fator para que ele não fosse considerado como uma variável numérica.\n\nmf &lt;- lm(severity ~ treat*factor(dose),\n         data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\n\nCom o modelo linear ajustado, foi feito a ANOVA usando a função anova().\n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEm relação ao fator tratamento, observa-se que o p-valor foi inferior ao nível de significância (5%), rejeitando a hipótese nula de que os grupos são iguais em função do tratamento aplicado.\nTambém nota-se que em relação ao fator dose, o p-valor foi inferior ao nível de significância (5%), rejeitando a hipótese nula de que os grupos são iguais em função das doses aplicadas.\nPor último também foi visto que a interação entre os fatores “tratamento” e “dose” foi significativo, indicando que a interação entre esses dois fatores interferem nas diferenças estatísticas entre os grupos."
  },
  {
    "objectID": "Aula7_quarto.html#teste-das-premissas-1",
    "href": "Aula7_quarto.html#teste-das-premissas-1",
    "title": "ANOVA",
    "section": "Teste das premissas",
    "text": "Teste das premissas\nAs premissas foram checadas através das funções simulateResiduals(), check_normality() e check_heteroscedasticity().\n\nplot(simulateResiduals(mf))\n\n\n\ncheck_normality(mf)\n\nWarning: Non-normality of residuals detected (p = 0.011).\n\ncheck_heteroscedasticity(mf)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nAs funções do pacote performance apresentaram problemas em relação à normalidade e homocedasticidade, no entanto, a função simulateResiduals() não demonstrou problema nas premissas."
  },
  {
    "objectID": "Aula7_quarto.html#teste-de-comparação-das-médias",
    "href": "Aula7_quarto.html#teste-de-comparação-das-médias",
    "title": "ANOVA",
    "section": "Teste de comparação das médias",
    "text": "Teste de comparação das médias\nEm seguida, foi feito a comparação entre as médias dos grupos usando as funções emmeans() e cld().\nPor se tratar de dois fatores, foi comparado as médias entre os grupos em função de cada fator, usando as fórmulas ~ treat|dose para comparar as médias dos tratamentos em função das doses e ~ dose|treat para comparar as médias das doses em função dos tratamentos.\n\nmf_medias &lt;- emmeans(mf, ~ treat|dose)\nmf_medias\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789\n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\ncld(mf_medias, Letters = letters)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  a    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   b   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  a    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(cld(mf_medias))\n\n\n\nmf_medias2 &lt;- emmeans(mf, ~dose|treat)\ncld(mf_medias2, Letters = letters)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  a    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   b   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  a    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  a    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(cld(mf_medias2))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNa montagem de uma tabela de comparação das médias entre os grupos, as letras maiúsculas são usadas para comparar as mesmas colunas, enquanto que as letras minúsculas são usadas para comparar as mesmas linhas"
  },
  {
    "objectID": "Aula8_quarto.html",
    "href": "Aula8_quarto.html",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "",
    "text": "O delineamento em blocos casualizado (DBC) envolve os três princípios da experimentação: repetição, casualização e controle local. Neste caso, as condições locais não são homogêneas e podem ter efeito significativo sobre os tratamentos, sendo necessário o uso de blocos para controlar uma variação conhecida do ambiente.\nAssim, a ANOVA contará com três fontes de variação: duas fontes de variação conhecidas (tratamento e bloco), e uma fonte de variação desconhecida (resíduo).\nVale destacar que no DBC não há interesse pela interação do bloco com o tratamento, sendo o bloco apenas para controlar uma possível variação sobre os tratamentos induzida por uma possível variação do ambiente.\n\n\nO conjunto de dados foi importado do Google Sheet através da função gsheet2tbl() do pacote gsheet.\nOs dados importados contam com três variáveis respostas: DFC, Ferrugem e Produtividade. Foram experimentados 8 tratamentos, com 4 blocos.\n\nlibrary(tidyverse)\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nPara cada variável resposta será feito uma ANOVA. Mas primeiro é necessário considerar o número dos tratamentos e os números dos blocos como fatores. Isso pode ser feito usando a função mutate().\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n\n\n\nPara cada variável resposta foi criado um gráfico de pontos com a média e o intervalo de confiança de cada tratamento. O gráfico foi feito usando as funções ggplot(), geom_jitter() e stat_summary(), com o argumento fun.data = \"mean_cl_boot\" (esse argumento cria a bola representando a média e as linhas representando o intervalo de confiança)\nDepois, os 3 gráficos foram colocados juntos através do pacote patchwork.\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.1, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\ndfc\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.1, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")\nfer\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"red\")\nprod\n\n\n\nlibrary(patchwork)\ndfc / fer / prod\n\n\n\n\n\n\n\nComo não há interesse da interação entre o bloco e o tratamento, é preciso ajustar o modelo linear de modo que o bloco seja considerado como efeito fixo. Isso pode ser feito usando a função lm() juntamente com a fórmula DFC ~ TRAT+BLOCO (o “+” garante que o BLOCO seja visto como efeito fixo)\n\naov_dfc &lt;- lm(DFC ~ TRAT+BLOCO,\n              data = soja)\n\nCom o modelo ajustado, é executado a ANOVA usando a função anova().\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPelo resultado da ANOVA, pode-se observar que o efeito dos tratamentos na váriavel DFC é significativo, enquanto que o efeito dos blocos não é significativo.\n\n\nAs premissas foram checadas através das funções check_heteroscedasticity() e check_normality()\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\n\nAmbas as premissas foram atendidas\n\n\n\nA comparação das médias entre os grupos foi realizada com as funções emmeans() e cld.\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_dfc, Letters = letters)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  a    \n 7      4.08 0.322 21     3.41     4.74  a    \n 5      4.20 0.322 21     3.53     4.87  a    \n 8      4.58 0.322 21     3.91     5.24  ab   \n 4      4.75 0.322 21     4.08     5.42  ab   \n 3      6.05 0.322 21     5.38     6.72   bc  \n 2      6.42 0.322 21     5.76     7.09    c  \n 1     10.88 0.322 21    10.21    11.54     d \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se a formação de 4 grupos estatisticamente distintos.\nA eficácia no controle do DFC pode ser calculado através da seguinte fórmula: Eficácia no controle (%) = (1- (emmean do tratamento/emmean da testemunha))*100\n\n\n\n\n\naov_fer &lt;- lm(FER ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n\nAmbas as premissas não foram atendidas.\n\n\n\n\nb &lt;- boxcox(lm(soja$FER ~ 1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER3 &lt;- (soja$FER ^ lambda - 1)/ lambda\n\n\n\n\n\naov_fer3 &lt;- lm(FER3 ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_fer3)\n\nAnalysis of Variance Table\n\nResponse: FER3\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.041641 0.0059488 12.9020 2.436e-06 ***\nBLOCO      3 0.005895 0.0019649  4.2616   0.01687 *  \nResiduals 21 0.009683 0.0004611                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCom os dados transformados, nota-se que o efeito dos blocos também é significante para variável resposta da ferrugem.\n\n\n\n\ncheck_normality(aov_fer3)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\ncheck_heteroscedasticity(aov_fer3)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\n\n\n\n\n\nmedias_fer2 &lt;- emmeans(aov_fer3, ~ TRAT)\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.637 0.0107 21    0.614    0.659\n 2     0.596 0.0107 21    0.574    0.618\n 3     0.553 0.0107 21    0.530    0.575\n 4     0.527 0.0107 21    0.505    0.550\n 5     0.539 0.0107 21    0.517    0.561\n 6     0.523 0.0107 21    0.501    0.545\n 7     0.545 0.0107 21    0.523    0.567\n 8     0.549 0.0107 21    0.527    0.572\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer2)\n\n         1        2        3        4        5        6        7       8\n1  [0.637]   0.1857   0.0004   &lt;.0001   &lt;.0001   &lt;.0001   0.0001  0.0002\n2  0.04058  [0.596]   0.1358   0.0039   0.0208   0.0020   0.0497  0.0880\n3  0.08380  0.04322  [0.553]   0.7032   0.9807   0.5313   0.9995  1.0000\n4  0.10920  0.06862  0.02540  [0.527]   0.9938   1.0000   0.9339  0.8261\n5  0.09775  0.05717  0.01395 -0.01145  [0.539]   0.9629   0.9999  0.9964\n6  0.11349  0.07292  0.02970  0.00429  0.01575  [0.523]   0.8261  0.6703\n7  0.09154  0.05097  0.00775 -0.01766 -0.00620 -0.02195  [0.545]  1.0000\n8  0.08725  0.04667  0.00345 -0.02195 -0.01050 -0.02624 -0.00429 [0.549]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_fer2, Letters = letters)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.523 0.0107 21    0.501    0.545  a    \n 4     0.527 0.0107 21    0.505    0.550  a    \n 5     0.539 0.0107 21    0.517    0.561  a    \n 7     0.545 0.0107 21    0.523    0.567  a    \n 8     0.549 0.0107 21    0.527    0.572  ab   \n 3     0.553 0.0107 21    0.530    0.575  ab   \n 2     0.596 0.0107 21    0.574    0.618   bc  \n 1     0.637 0.0107 21    0.614    0.659    c  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se a formação de 3 grupos estatisticamente distintos.\n\n\n\n\n\naov_prod &lt;- lm(PROD ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\n\nAmbas as premissas foram atendidas\n\n\n\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_prod, Letters = letters)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  a    \n 2      4935 201 21     4516     5354  ab   \n 8      5078 201 21     4659     5497  ab   \n 3      5110 201 21     4691     5529  ab   \n 5      5122 201 21     4703     5541  ab   \n 7      5128 201 21     4709     5546  ab   \n 4      5140 201 21     4721     5559  ab   \n 6      5256 201 21     4837     5675   b   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se a formação de 2 grupos estatisticamente distintos.\nA diferença de produtividade pode ser calculada pela seguinte fórmula: Diferença de produtividade = emmean do tratamento - emmean da testemunha\n\n\n\n\nmedias_prod_grupo &lt;- cld(medias_prod, Letters = letters)\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt; \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = \"text\", x = 1.2, y = 4200, label = \"A\")+\n  annotate(geom = \"text\", x = 2.3, y = 5000, label = \"AB\")\n\n\n\n\n\n\n\nUsando a função write_xlsx() do pacote writexl, é possível exportar a tabela de comparação das médias entre os grupos para um arquivo Excel.\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\na\n\n\n2\n2\n4935.00\nab\n\n\n8\n8\n5078.25\nab\n\n\n3\n3\n5110.00\nab\n\n\n5\n5\n5122.00\nab\n\n\n7\n7\n5127.50\nab\n\n\n4\n4\n5140.25\nab\n\n\n6\n6\n5256.25\nb\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")"
  },
  {
    "objectID": "Aula8_quarto.html#importação-dos-dados",
    "href": "Aula8_quarto.html#importação-dos-dados",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "",
    "text": "O conjunto de dados foi importado do Google Sheet através da função gsheet2tbl() do pacote gsheet.\nOs dados importados contam com três variáveis respostas: DFC, Ferrugem e Produtividade. Foram experimentados 8 tratamentos, com 4 blocos.\n\nlibrary(tidyverse)\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nPara cada variável resposta será feito uma ANOVA. Mas primeiro é necessário considerar o número dos tratamentos e os números dos blocos como fatores. Isso pode ser feito usando a função mutate().\n\nsoja &lt;- soja |&gt; \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))"
  },
  {
    "objectID": "Aula8_quarto.html#visualização-dos-dados",
    "href": "Aula8_quarto.html#visualização-dos-dados",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "",
    "text": "Para cada variável resposta foi criado um gráfico de pontos com a média e o intervalo de confiança de cada tratamento. O gráfico foi feito usando as funções ggplot(), geom_jitter() e stat_summary(), com o argumento fun.data = \"mean_cl_boot\" (esse argumento cria a bola representando a média e as linhas representando o intervalo de confiança)\nDepois, os 3 gráficos foram colocados juntos através do pacote patchwork.\n\ndfc &lt;- soja |&gt; \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.1, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\ndfc\n\n\n\nfer &lt;- soja |&gt; \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.1, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")\nfer\n\n\n\nprod &lt;- soja |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1, color = \"gray70\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"red\")\nprod\n\n\n\nlibrary(patchwork)\ndfc / fer / prod"
  },
  {
    "objectID": "Aula8_quarto.html#anova-dfc",
    "href": "Aula8_quarto.html#anova-dfc",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "",
    "text": "Como não há interesse da interação entre o bloco e o tratamento, é preciso ajustar o modelo linear de modo que o bloco seja considerado como efeito fixo. Isso pode ser feito usando a função lm() juntamente com a fórmula DFC ~ TRAT+BLOCO (o “+” garante que o BLOCO seja visto como efeito fixo)\n\naov_dfc &lt;- lm(DFC ~ TRAT+BLOCO,\n              data = soja)\n\nCom o modelo ajustado, é executado a ANOVA usando a função anova().\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPelo resultado da ANOVA, pode-se observar que o efeito dos tratamentos na váriavel DFC é significativo, enquanto que o efeito dos blocos não é significativo.\n\n\nAs premissas foram checadas através das funções check_heteroscedasticity() e check_normality()\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\n\nAmbas as premissas foram atendidas\n\n\n\nA comparação das médias entre os grupos foi realizada com as funções emmeans() e cld.\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT)\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias_dfc, Letters = letters)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  a    \n 7      4.08 0.322 21     3.41     4.74  a    \n 5      4.20 0.322 21     3.53     4.87  a    \n 8      4.58 0.322 21     3.91     5.24  ab   \n 4      4.75 0.322 21     4.08     5.42  ab   \n 3      6.05 0.322 21     5.38     6.72   bc  \n 2      6.42 0.322 21     5.76     7.09    c  \n 1     10.88 0.322 21    10.21    11.54     d \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se a formação de 4 grupos estatisticamente distintos.\nA eficácia no controle do DFC pode ser calculado através da seguinte fórmula: Eficácia no controle (%) = (1- (emmean do tratamento/emmean da testemunha))*100"
  },
  {
    "objectID": "Aula8_quarto.html#anova-fer",
    "href": "Aula8_quarto.html#anova-fer",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "",
    "text": "aov_fer &lt;- lm(FER ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n\nAmbas as premissas não foram atendidas.\n\n\n\n\nb &lt;- boxcox(lm(soja$FER ~ 1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER3 &lt;- (soja$FER ^ lambda - 1)/ lambda\n\n\n\n\n\naov_fer3 &lt;- lm(FER3 ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_fer3)\n\nAnalysis of Variance Table\n\nResponse: FER3\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.041641 0.0059488 12.9020 2.436e-06 ***\nBLOCO      3 0.005895 0.0019649  4.2616   0.01687 *  \nResiduals 21 0.009683 0.0004611                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCom os dados transformados, nota-se que o efeito dos blocos também é significante para variável resposta da ferrugem.\n\n\n\n\ncheck_normality(aov_fer3)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\ncheck_heteroscedasticity(aov_fer3)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\n\n\n\n\n\nmedias_fer2 &lt;- emmeans(aov_fer3, ~ TRAT)\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.637 0.0107 21    0.614    0.659\n 2     0.596 0.0107 21    0.574    0.618\n 3     0.553 0.0107 21    0.530    0.575\n 4     0.527 0.0107 21    0.505    0.550\n 5     0.539 0.0107 21    0.517    0.561\n 6     0.523 0.0107 21    0.501    0.545\n 7     0.545 0.0107 21    0.523    0.567\n 8     0.549 0.0107 21    0.527    0.572\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_fer2)\n\n         1        2        3        4        5        6        7       8\n1  [0.637]   0.1857   0.0004   &lt;.0001   &lt;.0001   &lt;.0001   0.0001  0.0002\n2  0.04058  [0.596]   0.1358   0.0039   0.0208   0.0020   0.0497  0.0880\n3  0.08380  0.04322  [0.553]   0.7032   0.9807   0.5313   0.9995  1.0000\n4  0.10920  0.06862  0.02540  [0.527]   0.9938   1.0000   0.9339  0.8261\n5  0.09775  0.05717  0.01395 -0.01145  [0.539]   0.9629   0.9999  0.9964\n6  0.11349  0.07292  0.02970  0.00429  0.01575  [0.523]   0.8261  0.6703\n7  0.09154  0.05097  0.00775 -0.01766 -0.00620 -0.02195  [0.545]  1.0000\n8  0.08725  0.04667  0.00345 -0.02195 -0.01050 -0.02624 -0.00429 [0.549]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_fer2, Letters = letters)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.523 0.0107 21    0.501    0.545  a    \n 4     0.527 0.0107 21    0.505    0.550  a    \n 5     0.539 0.0107 21    0.517    0.561  a    \n 7     0.545 0.0107 21    0.523    0.567  a    \n 8     0.549 0.0107 21    0.527    0.572  ab   \n 3     0.553 0.0107 21    0.530    0.575  ab   \n 2     0.596 0.0107 21    0.574    0.618   bc  \n 1     0.637 0.0107 21    0.614    0.659    c  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se a formação de 3 grupos estatisticamente distintos."
  },
  {
    "objectID": "Aula8_quarto.html#anova-prod",
    "href": "Aula8_quarto.html#anova-prod",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "",
    "text": "aov_prod &lt;- lm(PROD ~ TRAT+BLOCO,\n              data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\n\nAmbas as premissas foram atendidas\n\n\n\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\ncld(medias_prod, Letters = letters)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  a    \n 2      4935 201 21     4516     5354  ab   \n 8      5078 201 21     4659     5497  ab   \n 3      5110 201 21     4691     5529  ab   \n 5      5122 201 21     4703     5541  ab   \n 7      5128 201 21     4709     5546  ab   \n 4      5140 201 21     4721     5559  ab   \n 6      5256 201 21     4837     5675   b   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nObserva-se a formação de 2 grupos estatisticamente distintos.\nA diferença de produtividade pode ser calculada pela seguinte fórmula: Diferença de produtividade = emmean do tratamento - emmean da testemunha\n\n\n\n\nmedias_prod_grupo &lt;- cld(medias_prod, Letters = letters)\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt; \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\n  annotate(geom = \"text\", x = 1.2, y = 4200, label = \"A\")+\n  annotate(geom = \"text\", x = 2.3, y = 5000, label = \"AB\")\n\n\n\n\n\n\n\nUsando a função write_xlsx() do pacote writexl, é possível exportar a tabela de comparação das médias entre os grupos para um arquivo Excel.\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\na\n\n\n2\n2\n4935.00\nab\n\n\n8\n8\n5078.25\nab\n\n\n3\n3\n5110.00\nab\n\n\n5\n5\n5122.00\nab\n\n\n7\n7\n5127.50\nab\n\n\n4\n4\n5140.25\nab\n\n\n6\n6\n5256.25\nb\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")"
  },
  {
    "objectID": "Aula8_quarto.html#importação-dos-dados-1",
    "href": "Aula8_quarto.html#importação-dos-dados-1",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "Importação dos dados",
    "text": "Importação dos dados\nO conjunto de dados foi importado a partir do Google Sheet através da função gsheet2tbl() do pacote gsheet. Como os dados não estavam no formato de data frame, foi usado a função as.data.frame() para realizar a conversão.\nO conjunto de dados apresenta a severidade de uma doença em função do dia e do modo de irrigação.\n\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\ncurve = as.data.frame(curve)"
  },
  {
    "objectID": "Aula8_quarto.html#visualização-dos-dados-1",
    "href": "Aula8_quarto.html#visualização-dos-dados-1",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nPor ser um conjunto de dados que possui uma variável numérica em função de um fator temporal, foi construído um gráfico de linhas para exibir o progresso da severidade da doença em função dos dias. Para isso, foi usado as funções ggplot() juntamente a geom_point() e geom_line().\nTambém foram feitos gráficos separando os dados em função dos diferentes modos de irrigação utilizados no experimento.\n\ncurve |&gt; \n  group_by(day) |&gt; \n  summarise(severity_mean = mean(severity),\n            severity_sd = sd(severity)) |&gt; \n  ggplot(aes(day, severity_mean))+\n  geom_point(width = 0.05)+\n  geom_line()\n\n\n\ncurve |&gt; \n  group_by(day, Irrigation) |&gt; \n  summarise(severity_mean = mean(severity),\n            severity_sd = sd(severity)) |&gt; \n  ggplot(aes(day, severity_mean, color = Irrigation))+\n  geom_point(width = 0.05)+\n  geom_line()\n\n\n\ncurve |&gt; \n  group_by(day, Irrigation) |&gt; \n  summarise(severity_mean = mean(severity)) |&gt; \n  ggplot(aes(day, severity_mean))+\n  geom_point(width = 0.05)+\n  geom_line()+\n  facet_grid(~Irrigation)"
  },
  {
    "objectID": "Aula8_quarto.html#audpc",
    "href": "Aula8_quarto.html#audpc",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "AUDPC",
    "text": "AUDPC\nPara calcular a AUDPC (o mesmo que AACPD), foi usado o pacote epifitter junto com a função summarise(AUDPC()).\n\nlibrary(epifitter)\naudpc &lt;- curve |&gt; \n  group_by(Irrigation, rep) |&gt; \n  summarise(aacpd = AUDPC(day, severity))"
  },
  {
    "objectID": "Aula8_quarto.html#anova-da-audpc",
    "href": "Aula8_quarto.html#anova-da-audpc",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "ANOVA da AUDPC",
    "text": "ANOVA da AUDPC\nTendo os dados da AUDPC, o conjunto de dados foi ajustado para o modelo linear usando a função lm() e a fórmula aacpd ~ Irrigation + factor(rep), na qual as repetições foram considerados como efeito fixo.\nPosteriormente, foi realizado uma análise de variância.\n\naov_audpc &lt;- lm(aacpd ~ Irrigation + factor(rep),\n                data = audpc) \nanova(aov_audpc)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPelos resultados, percebe-se que tanto o modo de irrigação quanto as repetições tiveram efeitos pouco significativos em relação ao AUDPC.\nUsando os dados originais importados, foi também realizado uma ANOVA da severidade da doença em função do modo de irrigação interagindo com o fator dia, com as repetições novamente como efeito fixo.\n\naov_curve &lt;- lm(severity ~ Irrigation*day + rep,\n         data = curve)\nanova(aov_curve)\n\nAnalysis of Variance Table\n\nResponse: severity\n               Df  Sum Sq Mean Sq   F value Pr(&gt;F)    \nIrrigation      1 0.00067 0.00067    0.5419 0.4648    \nday             1 1.33121 1.33121 1082.0680 &lt;2e-16 ***\nrep             1 0.00009 0.00009    0.0732 0.7878    \nIrrigation:day  1 0.00070 0.00070    0.5716 0.4528    \nResiduals      55 0.06766 0.00123                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObserva-se que o fator dia teve um efeito significativo sobre a severidade da doença, enquanto que os outros componentes não tiveram efeitos sobre a variável.\n\nCoeficiente de variação\nO coeficiente de variação (CV) é um indicador da variabilidade de um conjunto de dados. Ele pode ser encontrado usando a função cv.model() do pacote agricolae.\n\nlibrary(agricolae)\ncv.model(aov_audpc)\n\n[1] 1.097572"
  },
  {
    "objectID": "Aula8_quarto.html#importação-dos-dados-2",
    "href": "Aula8_quarto.html#importação-dos-dados-2",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "Importação dos dados",
    "text": "Importação dos dados\nO conjunto de dados foi importado a partir do Google Sheet através da função gsheet2tbl() do pacote gsheet.\nEsses dados representam podridão de Fusarium em milho em parcelas subdivididas. Dentro de cada bloco foi casualizado os híbridos (tratamento primário). O método de aplicação foi casualizado dentro dos híbridos (tratamento secundário).\n\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")"
  },
  {
    "objectID": "Aula8_quarto.html#visualização-dos-dados-2",
    "href": "Aula8_quarto.html#visualização-dos-dados-2",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nForam criados dois gráficos de pontos com intervalos de confiança, sendo um gráfico sobre o índice e outro sobre a produtividade. Os gráficos foram criados usando as funções ggplot(), geom_jitter() e stat_summary (para criar os pontos médios e intervalos de confiança)\n\nmilho |&gt; \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")\n\n\n\nmilho |&gt; \n  ggplot(aes(method, yield))+\n  geom_jitter(width = 0.1, color = \"black\", alpha = 0.2)+\n  facet_grid(~hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"red\")"
  },
  {
    "objectID": "Aula8_quarto.html#modelo-para-parcela-subdividida---index",
    "href": "Aula8_quarto.html#modelo-para-parcela-subdividida---index",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "Modelo para parcela subdividida - index",
    "text": "Modelo para parcela subdividida - index\nEm relação à variável resposta de índice, o modelo do conjunto de dados foi ajustado para o modelo misto usando a função lmer() do pacote lme4. Para atribuir os efeitos fixos e aleatórios, foi usado a seguinte fórmula: index ~ hybrid*method + block + (1|block/hybrid), no qual os blocos estão como efeitos fixos e os híbridos como efeitos aleatórios.\n\nlibrary(lme4)\n\nmilho &lt;- milho |&gt; \n  mutate(block = as.factor(block))\n\nmix &lt;- lmer(index ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\n\nA análise de variância foi executada com a função Anova() do pacote car.\n\nlibrary(car)\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPode-se concluir que pelo menos um híbrido é diferente dos demais, assim como existe diferença significativa entre os métodos. A interação entre híbridos e métodos também resultou em uma diferença estatística.\n\nTeste das premissas\n\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix))\n\n\n\n\nA premissa da homocedasticidade não foi atendida, sendo necessário realizar transformação dos dados.\n\n\nTransformação com raiz quadrada\n\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0783  3   0.994305   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.970).\n\nplot(simulateResiduals(mix2))\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\nhist(residuals(mix2))\n\n\n\n\nDessa vez as premissas foram atendidas.\n\n\nComparação das médias entre os grupos\nO teste de comparação das médias entre os grupos foi realizado com as funções emmeans() e cld().\nComo a interação entre híbridos e métodos deu um valor significativo, o teste de comparação das médias foi tanta sobre os híbridos em função dos métodos, quando dos métodos em função dos híbridos.\n\nmedias_milho &lt;- emmeans(mix2,\n                        ~hybrid|method,\n                        type = \"response\") #Qaundo transforma dados, precisa colocar type = response\nmedias_milho2 &lt;- emmeans(mix2,\n                         ~method|hybrid,\n                         type = \"response\")\n\ncld(medias_milho, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.3 5155     4.50     44.7  A    \n 30K64        20.3 10.5 5155     4.93     46.1  A    \n 30F53 YH     24.5 11.5 5155     7.11     52.3  AB   \n 30F53 HX     25.0 11.6 5155     7.35     53.0  AB   \n 30S31YH      31.7 13.1 5155    11.20     62.6  AB   \n 30S31H       37.1 14.2 5155    14.52     70.2   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.2 5155     4.35     44.3  A    \n 30K64        21.3 10.8 5155     5.44     47.6  A    \n 30F53 HX     24.4 11.5 5155     7.07     52.2  A    \n 30F53 YH     26.0 11.9 5155     7.95     54.6  A    \n 30S31H       26.3 12.0 5155     8.11     55.0  A    \n 30S31YH      26.4 12.0 5155     8.16     55.1  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 11.5 5155     7.07     52.2  a    \n pin        25.0 11.6 5155     7.35     53.0  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 11.5 5155     7.11     52.3  a    \n silk       26.0 11.9 5155     7.95     54.6  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.5 5155     4.93     46.1  a    \n silk       21.3 10.8 5155     5.44     47.6  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.0 5155     8.11     55.0  a    \n pin        37.1 14.2 5155    14.52     70.2   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.0 5155     8.16     55.1  a    \n pin        31.7 13.1 5155    11.20     62.6  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.2 5155     4.35     44.3  a    \n pin        19.4 10.3 5155     4.50     44.7  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula8_quarto.html#modelo-para-parcela-subdividida---yield",
    "href": "Aula8_quarto.html#modelo-para-parcela-subdividida---yield",
    "title": "ANOVA em blocos casualizados e parcela subdividida",
    "section": "Modelo para parcela subdividida - yield",
    "text": "Modelo para parcela subdividida - yield\nOs mesmos processos foram repetidos para a variável resposta produtividade.\n\nmix3 &lt;- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), \n             data = milho)\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPelo menos um híbrido é diferente dos demais, assim como existe diferença significativa na interação híbrido com método\n\nTeste das premissas\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\nAs premissas foram atendidas.\n\n\nComparação das médias entre os grupos\n\nmedias_milho3 &lt;- emmeans(mix3,\n                        ~hybrid|method) \nmedias_milho4 &lt;- emmeans(mix3,\n                         ~method|hybrid)\n\ncld(medias_milho3, Letters = LETTERS)\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n 30S31YH    88.5 4.13 26.1     80.0     97.0  A    \n 30S31H     89.9 4.13 26.1     81.4     98.4  AB   \n 30F53 YH   96.5 4.13 26.1     88.0    105.0  ABC  \n 30F53 HX  105.5 4.13 26.1     97.0    114.0   BC  \n 30K64     108.0 4.13 26.1     99.5    116.5    C  \n BG7049H   109.2 4.13 26.1    100.7    117.6    C  \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n 30S31YH    90.9 4.13 26.1     82.4     99.4  A    \n 30F53 YH   95.3 4.13 26.1     86.8    103.8  A    \n 30S31H     95.6 4.13 26.1     87.1    104.1  A    \n 30F53 HX   99.7 4.13 26.1     91.2    108.2  AB   \n 30K64     101.6 4.13 26.1     93.1    110.1  AB   \n BG7049H   113.2 4.13 26.1    104.7    121.7   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld(medias_milho4, Letters = letters)\n\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     99.7 4.13 26.1     91.2    108.2  a    \n pin     105.5 4.13 26.1     97.0    114.0   b   \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     95.3 4.13 26.1     86.8    103.8  a    \n pin      96.5 4.13 26.1     88.0    105.0  a    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n silk    101.6 4.13 26.1     93.1    110.1  a    \n pin     108.0 4.13 26.1     99.5    116.5   b   \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n pin      89.9 4.13 26.1     81.4     98.4  a    \n silk     95.6 4.13 26.1     87.1    104.1   b   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      88.5 4.13 26.1     80.0     97.0  a    \n silk     90.9 4.13 26.1     82.4     99.4  a    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n pin     109.2 4.13 26.1    100.7    117.6  a    \n silk    113.2 4.13 26.1    104.7    121.7  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9_quarto.html",
    "href": "Aula9_quarto.html",
    "title": "Regressão",
    "section": "",
    "text": "library(tidyverse)\nlibrary(lme4)\nlibrary(car)"
  },
  {
    "objectID": "Aula9_quarto.html#importação-dos-dados",
    "href": "Aula9_quarto.html#importação-dos-dados",
    "title": "Regressão",
    "section": "Importação dos dados",
    "text": "Importação dos dados\nO conjunto de dados foi importado a partir do Google Sheet através da função gsheet2tbl() do pacote gsheet.\nEsse conjunto de dados é composto pelo trat, que é o percentual de sementes inoculados com patógenos e nplants, que é o número de plantas emergidas no campo. Estima-se que o aumento da concentração de inóculo irá diminuir a estande de plantas no cmapo. O fator de concentração de inóculo é um fator numérico contínuo.\n\nlibrary(gsheet)\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")"
  },
  {
    "objectID": "Aula9_quarto.html#visualização-dos-dados",
    "href": "Aula9_quarto.html#visualização-dos-dados",
    "title": "Regressão",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nForam criados gráficos de pontos com intervalos de confiança. Os gráficos foram criados usando as funções ggplot(), geom_jitter() e stat_summary (para criar os pontos médios e intervalos de confiança).\nTambém foi usada a função geom_smooth() com o argumento method = \"lm\" para criar uma linha de tendência no gráfico ajustado ao modelo linear, mostrando a tendência que os dados possuem de aumentar ou diminuir em função do eixo X.\n\nestande |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.1, color = \"gray\")+\n  facet_wrap(~exp)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")+\n  geom_smooth(method = \"lm\", se = F)\n\n\n\nestande |&gt; \n  ggplot(aes(trat, nplants, color = factor(exp)))+\n  geom_jitter(width = 0.1, color = \"gray\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")+\n  geom_smooth(method = \"lm\", se = F)"
  },
  {
    "objectID": "Aula9_quarto.html#regressão-linear-do-experimento-1",
    "href": "Aula9_quarto.html#regressão-linear-do-experimento-1",
    "title": "Regressão",
    "section": "Regressão linear do experimento 1",
    "text": "Regressão linear do experimento 1\nInicialmente foi filtrado apenas o experimento 1 do conjunto de dados usando a função filter().\n\nexp1 &lt;- estande |&gt; \n  filter(exp == 1)\n\nDepois foi plotado um gráfico do experimento 1 usando as funções ggplot(), geom_point() e geom_smooth() (dessa vez sem nenhum ajuste de modelo).\n\nexp1 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F)\n\n\n\n\nPode-se observar pelo gráfico que a linha de tendência se assemelha a uma reta (modelo linear).\nPara ajustar os dados em um modelo linear, foi usada a função lm().\n\nlm1 &lt;- lm(nplants ~ trat,\n          data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\nA partir da função summary(), é possível inferir que a taxa de redução da variável resposta em função do eixo X é de -0.24, ou seja, para cada unidade de X reduz o Y em -0.24.\nAlém disso, o p-valor é informado, sendo igual a 0.2066, ou seja, é superior ao nível de significância e não se pode rejeitar a hipótese nula (Ho: a taxa de redução é igual a 0).\nOutra alternativa para realizar a regressão linear é usando a função glm() e o argumento family = \"gaussian\".\n\nglm1 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\n\nA família gaussiana envolve o mesmo método do “lm”, resultando na mesma taxa de redução."
  },
  {
    "objectID": "Aula9_quarto.html#regressão-linear-do-experimento-2",
    "href": "Aula9_quarto.html#regressão-linear-do-experimento-2",
    "title": "Regressão",
    "section": "Regressão linear do experimento 2",
    "text": "Regressão linear do experimento 2\nInicialmente foi filtrado apenas o experimento 2 do conjunto de dados usando a função filter().\n\nexp2 &lt;- estande |&gt; \n  filter (exp == 2)\n\nO mesmo gráfico foi montado para o experimento 2.\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm, se = F)\n\n\n\n\nPelo gráfico é possível observar uma diminuição dos valores de Y em função do eixo X.\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\nO resultado do modelo linear indica que a taxa de redução desses dados é de -0.70, ou seja, para cada unidade de X reduz o Y em -0.70.\nNesse experimento nota-se que o p-valor foi inferior ao nível de significância, indicando que a hipótese nula de que a taxa de redução é igual a 0 é rejeitada, ou seja, há uma regressão.\nAjustando o modelo pelo método do GLM, pode ser utilizado duas famílias: family = \"gaussian\" e family = \"log\".\n\nglm2 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm2)\n\n[1] 194.9597\n\nglm2b &lt;- glm(nplants ~ trat,\n             family = poisson(link = \"log\"),\n             data = exp2)\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\nA função AIC() compara os dois métodos (famílias diferentes) e fornece qual deles melhor representa o conjunto de dados. Sempre o menor valor é o mais recomendado. Nesse caso, usando a família gaussiana, o valor de AIC foi menor, sendo o modelo que melhor representa os dados."
  },
  {
    "objectID": "Aula9_quarto.html#regressão-linear-do-experimento-3",
    "href": "Aula9_quarto.html#regressão-linear-do-experimento-3",
    "title": "Regressão",
    "section": "Regressão linear do experimento 3",
    "text": "Regressão linear do experimento 3\nInicialmente foi filtrado apenas o experimento 3 do conjunto de dados usando a função filter().\n\nexp3 &lt;- estande |&gt; \n  filter (exp == 3)\n\nO mesmo gráfico foi montado para o experimento 3.\n\nexp3 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm, se = F)\n\n\n\n\nPelo gráfico é possível observar uma diminuição dos valores de Y em função do eixo X.\n\nlm3 &lt;- lm(nplants ~ trat,\n          data = exp3)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\nO resultado do modelo linear indica que a taxa de redução desses dados é de -0.76, ou seja, para cada unidade de X reduz o Y em -0.76.\nNesse experimento nota-se que o p-valor foi inferior ao nível de significância, indicando que a hipótese nula de que a taxa de redução é igual a 0 é rejeitada, ou seja, há uma regressão.\nO coeficiente de determinação (adjusted R-squared) fornecido é igual a 59%, o que indica que 59% da variabilidade do Y (número de plantas) é explicado pelo X (inóculo), sendo o máximo desse coeficiente igual a 1.\n\nglm3 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm3)\n\n[1] 185.0449\n\nglm3b &lt;- glm(nplants ~ trat,\n             family = poisson(link = \"log\"),\n             data = exp3)\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3b) #melhor qualidade de ajuste, quanto menor é melhor (mais ajustado)\n\n[1] 183.9324\n\n\nPara esse conjunto de dados, a família log resultou em um menor valor de AIC, o que indica que esse modelo melhor representa os dados que a família gaussiana.\nTransformando o log dos tratamentos, os dados ficam mais linearizados (diminui a curva).\n\nexp3 |&gt; \n  ggplot(aes(log(trat), nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F)"
  },
  {
    "objectID": "Aula9_quarto.html#regressão-linear-geral",
    "href": "Aula9_quarto.html#regressão-linear-geral",
    "title": "Regressão",
    "section": "Regressão linear geral",
    "text": "Regressão linear geral\nPegandos os dados inteiros, foi realizado o ajuste do modelo usando o GLM tanto com a família gaussianda quanto por log e depois foi comparado os dois modelos com o AIC.\n\nlibrary(lme4)\nglm4 &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = \"gaussian\",\n            data = estande)\nsummary(glm4)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glm4)\n\n[1] 592.8402\n\nglm4b &lt;- glmer(nplants ~ trat + (trat|exp),   #(trat|exp) é o efeito aleatório\n             family = poisson(link = \"log\"),\n             data = estande)\nsummary(glm4b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glm4b)\n\n[1] 660.7282\n\n\nUsando a família gaussianda, nota-se que o AIC obtido foi menor, indicando que, no geral, esse modelo é o que melhor representa o conjunto de dados."
  },
  {
    "objectID": "Aula9_quarto.html#visualização-dos-dados-1",
    "href": "Aula9_quarto.html#visualização-dos-dados-1",
    "title": "Regressão",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\n\nwm |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se = F)+\n  theme_minimal()"
  },
  {
    "objectID": "Aula9_quarto.html#regressão-linear-1",
    "href": "Aula9_quarto.html#regressão-linear-1",
    "title": "Regressão",
    "section": "Regressão linear",
    "text": "Regressão linear\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\nAjustando o conjunto de dados ao modelo linear, foi obtido uma taxa de redução de -9.261.\n\nlibrary(broom)\nmofo2 &lt;- wm |&gt; \n  group_by(study) |&gt; \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\n\ndf&lt;- mofo2 |&gt; \n  filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\n#Histograma da produtividade quando incidência é 0\np1 &lt;- mofo2 |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Intercept\", y = \"frequency\")\np2 &lt;- mofo2 |&gt; \n  filter(term == \".$inc\") |&gt; \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Slopes\", y = \"frequency\")\nlibrary(patchwork)\np1+p2\n\n\n\n\nUm outro ajuste de modelo foi utilizado para o conjunto de dados, considerando desa vez um efeito aleatório de incidência por estudos.\n\nlibrary(lme4)\nmofo3 &lt;- lmer(yld ~ inc + (inc|study), data = wm, REML = F)\nsummary(mofo3)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\n\nEsta estimativa de taxa de redução de -17 é muito mais confiável, uma vez que os outros métodos subestimam os valores.\nA incidência está causando uma redução na produtividade de -17kg (à medida que a incidência aumenta, a produtividade diminui em 17kg)\n\nAnova(mofo3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(&gt;Chisq)    \ninc 141.09  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(mofo3, method = \"Wald\")\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219"
  },
  {
    "objectID": "Aula9_quarto.html#visualização-dos-dados-2",
    "href": "Aula9_quarto.html#visualização-dos-dados-2",
    "title": "Regressão",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nO gráfico montado apresenta tanto a linha de tendência ajustada no modelo linear quanto a linha de tendência ajustada no modelo quadrático, usando a função geom_smooth() e o argumento formula = y ~poly(x,2).\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = lm, se = FALSE,\n              formula = y ~poly(x,2))+ #Modelo quadrático\n  geom_smooth(method = lm, se = F, color = \"red\") #Modelo linear"
  },
  {
    "objectID": "Aula9_quarto.html#regressão",
    "href": "Aula9_quarto.html#regressão",
    "title": "Regressão",
    "section": "Regressão",
    "text": "Regressão\nPara comparar qual é o melhor ajuste de modelo que representa o conjunto de dados, foi realizado o modelo de primeira ordem e de segunda ordem e depois eles foram comparados usando a função AIC().\n\nexp2$trat2 &lt;- exp2$trat^2 #Foi elevado ao quadrado para realizar o modelo quadrático, adicionar um coeficiente\n\n\n#Primeira ordem\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n#Segunda ordem ou quadrático\nlm3 &lt;- lm(nplants ~ trat + trat2,\n          data = exp2)\nsummary(lm3) #R deu 0.49 --&gt; explica melhor a variação dos dados se comparado ao de primeira ordem\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nPelo valor do AIC, observa-se que o modelo quadrático melhor representa o conjunto de dados.\nPara formular a função do modelo quadrático, é preciso observar os valores informados no summary()\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\n\nA função do modelo quadrático é y = 66,3 - 1,77xtrat + 0,02xtrat^2"
  },
  {
    "objectID": "Aula9_quarto.html#usando-o-pacote-agror",
    "href": "Aula9_quarto.html#usando-o-pacote-agror",
    "title": "Regressão",
    "section": "Usando o pacote AgroR",
    "text": "Usando o pacote AgroR\nAtravés do pacote AgroR, é possível criar os modelos de maneira mais fácil usando a função polynomial() e especificando o grau do modelo.\n\nlibrary(AgroR)\n\nwith(exp2, polynomial(trat, nplants, grau = 1))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 60.9857143  3.6304377 16.798447 4.929311e-14\ntrat        -0.7006912  0.1605226 -4.365063 2.473272e-04\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df      SSq       MSQ        F      p-value\nLinear     1 3196.203 3196.2031 21.82329 0.0001899378\nDeviation  4 1054.172  263.5430  1.79944 0.1729687460\nResidual  18 2636.250  146.4583                      \n\n\n[[1]]\n\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\nNormalmente não se utiliza o modelo de grau 3, pois não dá para explicar biologicamente a razão do dado estar aumentando e diminuindo."
  },
  {
    "objectID": "Aula9_quarto.html#visualização-dos-dados-3",
    "href": "Aula9_quarto.html#visualização-dos-dados-3",
    "title": "Regressão",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\n\npyra2 |&gt; \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  geom_smooth(span = 3, se = FALSE)+\n  facet_wrap(~code)\n\n\n\n\nNota-se que o conjunto de dados não segue o modelo linear e nem o modelo quadrático."
  },
  {
    "objectID": "Aula9_quarto.html#calculando-ec50-redução-da-germinação-em-50",
    "href": "Aula9_quarto.html#calculando-ec50-redução-da-germinação-em-50",
    "title": "Regressão",
    "section": "Calculando EC50 (redução da germinação em 50%)",
    "text": "Calculando EC50 (redução da germinação em 50%)\nComo o conjunto de dados envolve a aplicação de produto em diferentes doses para o controle de germinação do fungo, é possível calcular o EC50, ou seja, a dose em que a redução da germinação é de 50%. Para isso foi usado o pacote drc e a função ED(). Todavia, antes de se calcular a EC50, é preciso ajustar o conjunto de dados em um modelo não-linear, usando a função drm() e o argumento fct = LL.3() (log-logistic de 3 parâmetros).\n\nlibrary(drc)\n\nisolado165 &lt;- pyra2 |&gt; \n  filter(code == \"165\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado165,\n            fct = LL.3())\nAIC(drc1) \n\n[1] 31.55522\n\nplot(drc1) #Para visualizar se o ajuste está bom\n\n\n\nED(drc1, 50, interval = \"delta\") #O interval = delta fornece o intervalo de confiança\n\n\nEstimated effective doses\n\n       Estimate Std. Error   Lower   Upper\ne:1:50  0.55840    0.11420 0.19498 0.92182\n\n\nPara o isolado 165, estima-se o EC50 no valor de dose 0.55\nÉ possível estimar o EC50 de mais de um isolado ao mesmo tempo usando o pacote ec50estimator e a função estimate_EC50(). Novamente foi usado o argumento fct = drc::LL.3().\n\nlibrary(ec50estimator)\n\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = pyra2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\ndf_ec50\n\n      ID strata   Estimate  Std..Error        Lower     Upper\n1    152        0.44435629 0.077789240  0.196796213 0.6919164\n2    153        0.20379664 0.042373512  0.068945217 0.3386481\n3    164        0.50775844 0.047248266  0.357393370 0.6581235\n4    165        0.55839613 0.114195113  0.194976315 0.9218159\n5    169        0.14722311 0.009555688  0.116812646 0.1776336\n6    170        0.37503889 0.043207328  0.237533889 0.5125439\n7    186        0.57975744 0.013332268  0.537328208 0.6221867\n8    187        0.21563338 0.036639446  0.099030315 0.3322365\n9    188        0.15297172 0.004284691  0.139335920 0.1666075\n10   189        0.53106193 0.023130936  0.457448972 0.6046749\n11 FGT05        0.04483862 0.019290890 -0.016553601 0.1062308\n12 FGT06        0.54497946 0.034834602  0.434120211 0.6558387\n13 FGT07        0.88770053 0.079917704  0.633366725 1.1420343\n14 FGT28        0.22608141 0.033600742  0.119148854 0.3330140\n15 FGT29        0.23601652 0.034933881  0.124841318 0.3471917\n16 FGT33        0.10481627 0.013065221  0.063236910 0.1463956\n17 FGT34        0.14773114 0.047003373 -0.001854568 0.2973169\n18 FGT35        0.20315392 0.038984604  0.079087515 0.3272203\n19 FGT42        0.45000559 0.059685890  0.260058448 0.6399527\n20 FGT43        0.49589549 0.060850771  0.302241178 0.6895498\n\n\nPode-se também criar um gráfico que permite visualizar quais isolados são mais sensíveis e quais são menos sensíveis ao produto.\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper))+\n  coord_flip()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Seja bem-vindo!",
    "section": "",
    "text": "Sobre mim\nOlá! Eu me chamo Carlos Akira Komoli Utiamada, sou Engenheiro Agrônomo pela Universidade Estadual de Londrina (UEL) e atualmente sou mestrando do programa de pós-graduação em Fitopatologia da Universidade Federal de Viçosa (UFV). No momento estou atuando no Laboratório de Genética e Genômica da Interação Planta-Patógeno, dentro do Instituto de Biotecnologia Aplicada à Agropecuária (BIOAGRO), sob orientação do professor Sérgio Herminio Brommonschenkel.\nSobre o site\nEste website foi criado através do Quarto Markdown para a disciplina FIP606 - Análise e visualização de Dados em Fitopatologia, ministrada pelo professor Emerson M. Del Ponte. Neste site, você encontrará o material da disciplina e informações extras trazidas por mim, começando desde o básico do Software R até as principais análises estatísticas realizadas na área da Agronomia e Fitopatologia.\nSinta-se à vontade para entrar em contato comigo se tiver alguma dúvida e tenha bons estudos!\n\n\n Back to top"
  }
]