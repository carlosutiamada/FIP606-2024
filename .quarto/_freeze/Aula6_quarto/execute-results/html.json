{
  "hash": "e5e0671bb982f4a4742ef425fbe74cc1",
  "result": {
    "markdown": "---\ntitle: \"Teste-t\"\nformat: html\nmessage: false\nwarning: false\n---\n\n\n# Estatística Inferencial\n\nDiferentemente da estatística descritiva, a estatística inferencial dedica-se à extrapolação de conclusões acerca de uma população maior, baseando-se em uma amostra de dados.\n\nEste ramo utiliza métodos estatísticos para testar hipóteses e estimar parâmetros, possibilitando inferências sobre características da população a partir da análise de amostras.\n\n**Testes de Hipóteses**: Os testes de hipóteses são procedimentos que permitem tomar decisões sobre a população com base em amostras de dados. Utilizam-se para determinar se um resultado observado em dados de amostra pode ser atribuído ao acaso ou se é estatisticamente significativo.\n\n**P-Valor (Valor de Probabilidade)**: O valor de p é uma medida que indica a probabilidade de observar os resultados encontrados, ou resultados mais extremos, sob a suposição de que a hipótese nula é verdadeira. Valores de p baixos (tipicamente menor que 0,05) sugerem que é improvável obter tais resultados por acaso, levando à rejeição da hipótese nula.\n\nA principal diferença entre a estatística descritiva e estatística inferencial mais notável entre estes dois ramos reside na abordagem dos dados: enquanto a Estatística Descritiva concentra-se na descrição e síntese das características dos dados coletados, a Estatística Inferencial ocupa-se com a generalização dessas observações para populações maiores, permitindo a formulação de inferências e previsões.\n\n# Premissas\n\nTodos os testes estatísticos têm premissas de base que precisam ser atendidas para que o teste forneça resultados válidos em relação ao parâmetro que está sendo calculado. Os testes estatísticos devem atender às premissas de normalidade e homocedasticidade.\n\n**Normalidade**: A distribuição do conjunto de dados segue uma distribuição normal. Caso essa premissa não seja atendida, os dados devem ser trabalhados com testes não-paramétricos. A normalidade em testes estatísticos entre dois grupos pode ser calculada através do Shapiro-test.\n\n![Normalidade](C:/Users/carlo/Documents/GitHub/FIP606-2024/Normal.png)\n\n**Homocedasticidade**: as variâncias entre os dois grupos estudados são homogêneas, ou seja, similares. Essa premissa pode ser calculada por teste de variância.\n\n::: callout-note\nA premissa da homocedasticidade tem maior peso que a premissa da normalidade. Portanto, não se deve trabalhar com dados com variâncias heterogêneas.\n:::\n\n# Teste-t\n\nO teste t-Student, ou simplesmente teste-t, é o método mais utilizado para se avaliar as diferenças entre as médias entre dois grupos. É um teste de hipótese que usa conceitos estatísticos para rejeitar ou não uma hipótese nula quando a estatística de teste (t) segue uma distribuição *t* de Student.\n\nAs hipóteses formuladas em um teste-t comparam as médias entre dois grupos, podendo estas serem dependentes ou independentes.\n\n-   **Hipótese nula (Ho)**: a média do grupo 1 é igual a média do grupo 2\n-   **Hipótese alternativa (Ha)**: a média do grupo 1 é diferente da média do grupo 2\n\nTendo formulado as hipóteses, o teste-t irá calcular o valor de *t* e vai aplicá-lo à função densidade de probabilidade da distribuição *t* de Student medindo o tamanho da área abaixo dessa função para valores maiores ou iguais a *t*. Essa área representa a probabilidade da média dessa(s) amostra(s) em questão ter(em) apresentado o(s) valor(es) observado(s) ou algo mais extremo. Se a probabilidade desse resultado ter ocorrido for muito pequena, podemos concluir que o resultado observado é estatisticamente relevante. Essa probabilidade também é chamada de p-valor ou valor *p*.\n\n![Teste-t](C:/Users/carlo/Documents/GitHub/FIP606-2024/TesteT.png)\n\nCaso o nível de significância do p-valor for de 5% e a área abaixo da função densidade de probabilidade da distribuição *t* de Student seja menor do que 5%, pode-se afirmar que a hipótese nula é rejeitada com nível de confiança de 95%.\n\nNote que não rejeitar a hipótese nula não é a mesma coisa que afirmar que a hipótese alternativa é válida com o mesmo nível de confiança. Isso seria uma interpretação incorreta do teste.\n\n# Teste de Hipótese entre dois grupos independentes\n\nDois grupos independentes podem ser formados de duas maneiras distintas: extraindo-se uma amostra da população A e outra amostra da população B; ou indivíduos da mesma população foram alocados aleatoriamente a um dos dois tratamentos em estudo.\n\nUm exemplo típico de duas amostras independentes é quando temos um grupo experimental e um grupo controle.\n\n## Importação de dados\n\nO conjunto de dados foi importado do Google Sheet usando a função `gsheet2tbl()` do pacote `gsheet`. Nesse conjunto existem dois grupos independentes: um grupo de plantas em que foi aplicado Mg2 e um grupo de plantas controle (sem aplicação).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nmg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\nmg\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 3\n   trat      rep  comp\n   <chr>   <dbl> <dbl>\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n```\n:::\n:::\n\n\nPodemos observar que o conjunto de dados está no formato longo. Para o teste-t, é preciso que os dados estejam no formato largo, portanto eles serão transformados através da função `pivot_wider()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyr)\nlibrary(tidyverse)\n\nmg2 <- mg |> \n  pivot_wider(names_from = trat,\n              values_from = comp)\n```\n:::\n\n\n## Visualização dos dados\n\nO conjunto de dados pode ser visualizado por meio de um boxplot, criado através da função `ggplot()` juntamente a `geom_boxplot()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmg |> \n  ggplot(aes(trat, comp))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula6_quarto_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nAtravés do boxplot é possível assumir visualmente que os grupos seguem uma distribuição normal (pela simetria do boxplot formado) e que possuem variância homogênea (a estrutura dos dois boxplot são similares), mas os testes de premissas ainda devem ser feitos para confirmar.\n\n## Teste de premissas\n\nPara avaliar se o conjunto de dados segue uma distribuição normal, é preciso ser feito o Shapiro-test para cada um dos grupos. Esse teste pode ser realizada usando a função `shapiro.test()`. A função `hist()` também pode ser utilizada para observar visualmente se a distribuição dos dados é normal ou não.\n\nComo qualquer outro teste estatístico, o Shapiro-test também formula hipótese nula e alternativa. A **Hipótese nula (Ho)** é que a distribuição do conjunto de dados segue uma distribuição normal, enquanto que a **Hipótese alternativa (Ha)** diz que a distribuição dos dados não segue uma distribuição normal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(mg2$control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n```\n:::\n\n```{.r .cell-code}\nhist(mg2$control)\n```\n\n::: {.cell-output-display}\n![](Aula6_quarto_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshapiro.test(mg2$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n```\n:::\n\n```{.r .cell-code}\nhist(mg2$Mg2)\n```\n\n::: {.cell-output-display}\n![](Aula6_quarto_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\nObserva-se que em ambos os grupos o p-valor é superior ao nível de significância de 5%, portanto não se rejeita a hipótese nula e a distribuição pode ser considerada normal.\n\nOutra forma visual de verificar a normalidade dos dados do grupo é através das funções `qqnorm()` e `qqline()`. Conforme os pontos são mais próximos à reta, mais os dados seguem a normalidade.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(mg2$control)\nqqline(mg2$control)\n```\n\n::: {.cell-output-display}\n![](Aula6_quarto_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n```\n\n::: {.cell-output-display}\n![](Aula6_quarto_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\nPara verificar se as variâncias dos dois grupos são homogêneas, pode ser utilizado a função `var.test()`. Do mesmo modo, a **Hipótese nula (Ho)** diz que as variâncias entre os dois grupos são homogêneas, enquanto que a **Hipótese alternativa (Ha)** diz que as variâncias não são homogêneas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(mg2$control, mg2$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n```\n:::\n:::\n\n\nO p-valor foi maior que o nível de significância (5%), portanto não se rejeita a hipótese nula que as variâncias são homogêneas.\n\n## Teste de Hipótese\n\nVisto que as premissas foram atendidas, o próximo passo é o teste de hipótese propriamente dito. O teste-t é executado através da função `t.test()`, no qual devem ser especificados os dois grupos que serão analisados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteste1 <- t.test(mg2$Mg2, mg2$control)\nteste1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n```\n:::\n:::\n\n\nObserva-se que o p-valor foi muito inferior ao nível de significância de 5%, rejeitando a hipótese nula de que as médias entre os dois grupos são iguais. Logo, pode-se concluir que os dois grupos diferem estatisticamente um do outro.\n\nCaso as variâncias entre os dois grupos fossem heterogêneas, poderia ser adicionado o argumento `var.equal = FALSE` no teste-t.\n\nUsando a função `report()` do pacote `report`, um resumo da análise é montada automaticamente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report)\nreport(teste1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n```\n:::\n:::\n\n\n# Teste de Hipótese entre dois grupos dependentes\n\nDois grupos são considerados dependentes quando as observações em um grupo estão relacionadas de alguma forma às observações no outro grupo, ou seja, as amostras são provenientes dos mesmos indivíduos.\n\nIsso é muito comum para medições repetidas no mesmo grupo de sujeitos, ou seja, quando o mesmo grupo de sujeitos é medido em diferentes momentos ou sob diferentes condições.\n\n## Importação dos dados\n\nO conjunto de dados foi importado do Google Sheet usando a função `gsheet2tbl()` do pacote `gsheet`. Nesse conjunto existem dois grupos dependentes: avaliações realizadas sem ajuda de um instrumento e avaliações realizadas com ajuda de um instrumento sobre o mesmo conjunto de indivíduos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n```\n:::\n\n\nA função `pivot_wider()` foi usada para transformar o conjunto de dados de formato longo para formato largo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala2 <- escala |> \n  select(assessment, rater, acuracia) |> \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n```\n:::\n\n\n## Visualização dos dados\n\nA visualização dos dados foi feita com as funções `ggplot()` e `geom_boxplot()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala |> \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula6_quarto_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nApenas pelo gráfico é possível observar que a estutura dos dois grupos é diferente um do outro, podendo indicar variâncias heterogêneas.\n\n## Teste de premissas\n\nFoi usada a função `shapiro.test()` para cada grupo para determinar se eles seguem normalidade ou não.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(escala2$Unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(escala2$Aided1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n```\n:::\n\n```{.r .cell-code}\n#Em ambos os testes de normalidade, não rejeitamos a hipótese nula --> tem distribuição normal\n```\n:::\n\n\nEm ambos os testes, o p-valor foi inferior ao nível de significância, indicando que a hipótese nula deve ser rejeitada e que os conjuntos de dados não seguem uma distribuição normal.\n\nEm seguida foi realizado o teste de variância pela função `var.test()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(escala2$Unaided, escala2$Aided1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n```\n:::\n:::\n\n\nNovamente o p-valor foi inferior a 5%, indicando que as variâncias são heterogêneas.\n\n## Teste de Hipótese\n\nPara este caso de conjunto de dados onde os dois grupos são dependentes e apresentam variâncias heterogêneas, o teste-t é realizado com a função `t.test()` usando os argumentos `paired = TRUE` e `var.equal = FALSE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n```\n:::\n:::\n\n\nComo o p-valor foi inferior ao nível de significância, rejeitamos a hipótese nula de que os dois grupos são iguais.\n\n# Teste não paramétrico\n\nOs testes não-paramétricos são utilizados quando o conjunto de dados experimentados não segue uma distribuição normal. Dessa forma é necessário aplicar outros testes estatísticos para analisar dois grupos.\n\n![Testes não-paramétricos](C:/Users/carlo/Documents/GitHub/FIP606-2024/Testes.jpg)\n\nComo observado na imagem acima, os testes de Mann-Whitney e de Wilcoxon podem ser usados substituindo o teste-t para análises não-paramétricos de apenas 2 grupos, sendo que o teste de Mann-Whitney é usado para 2 grupos independentes e o teste de Wilcoxon para dois grupos dependentes.\n\n## Teste de premissas\n\nUsando o mesmo conjunto de dados da análise anterior, observa-se que nem a premissa de normalidade e nem a premissa de homocedasticidade foram atendidas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(escala2$Unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(escala2$Aided1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n```\n:::\n\n```{.r .cell-code}\nvar.test(escala2$Aided1, escala2$Unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  escala2$Aided1 and escala2$Unaided\nF = 0.047668, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.01184004 0.19191079\nsample estimates:\nratio of variances \n        0.04766793 \n```\n:::\n:::\n\n\n## Teste de Hipótese\n\nComo o conjunto de dados não apresenta uma distribuição normal, não tem variâncias homogêneas e envolve dois grupos dependentes, será aplicado o teste de Wilcoxon através da função `wilcox.test()`, usando o argumento `paired = TRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nObserva-se que o p-valor é inferior ao nível de significância, indicando que a hipótese nula de que os dois grupos são iguais é rejeitada.\n",
    "supporting": [
      "Aula6_quarto_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}